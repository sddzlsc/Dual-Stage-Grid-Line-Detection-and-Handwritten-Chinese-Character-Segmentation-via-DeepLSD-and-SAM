"""
ä½¿ç”¨DeepLSDæ£€æµ‹å›¾åƒä¸­çš„æ¨ªçº¿å’Œç«–çº¿ - äºŒæ¬¡æ£€æµ‹å»å¹²æ‰°æ¨¡å¼
åŸºäºDeepLSD-mainæ–‡ä»¶å¤¹ä¸­çš„ä»£ç 

ğŸ”§ è°ƒæ•´å‚æ•°å»é™¤å¹²æ‰°çº¿:
--------------------
åœ¨main()å‡½æ•°çš„é…ç½®åŒºåŸŸå¯ä»¥è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š

1. GRAD_THRESH (æ¢¯åº¦é˜ˆå€¼)
   - é»˜è®¤å€¼: 3 (æ­£å¸¸æ£€æµ‹)
   - æ¨èå€¼: 5-10 (å»é™¤æ›´å¤šå¹²æ‰°çº¿)
   - è¯´æ˜: å€¼è¶Šé«˜ï¼Œæ£€æµ‹è¶Šä¸¥æ ¼ï¼ŒçŸ­çº¿å’Œå¼±çº¿ä¼šè¢«è¿‡æ»¤

2. MIN_LENGTH_RATIO (æ¨ªçº¿æœ€å°é•¿åº¦æ¯”ä¾‹)
   - é»˜è®¤å€¼: 0.05 (å›¾åƒå¯¹è§’çº¿çš„5%)
   - æ¨èå€¼: 0.03-0.10
   - è¯´æ˜: äºŒæ¬¡æ£€æµ‹æ—¶è¿‡æ»¤çŸ­äºæ­¤é•¿åº¦çš„æ¨ªçº¿

3. ENDPOINT_DISTANCE_THRESHOLD (ç«–çº¿ç«¯ç‚¹è·ç¦»é˜ˆå€¼)
   - é»˜è®¤å€¼: 10 åƒç´ 
   - æ¨èå€¼: 5-15
   - è¯´æ˜: åªä¿ç•™ä¸Šä¸‹ç«¯ç‚¹éƒ½åœ¨æ­¤è·ç¦»å†…æ¥è¿‘æ¨ªçº¿çš„ç«–çº¿
   
4. MERGE_LINES (åˆå¹¶ç›¸è¿‘çº¿æ®µ)
   - é»˜è®¤å€¼: True
   - è¯´æ˜: æ˜¯å¦è‡ªåŠ¨åˆå¹¶è·ç¦»å¾ˆè¿‘çš„çº¿æ®µ

5. SAMå‚æ•° (æ§åˆ¶æ£€æµ‹å¯†åº¦ï¼Œé¿å…è¿‡åº¦åˆ†å‰²)
   - SAM_POINTS_PER_SIDE: é‡‡æ ·ç‚¹å¯†åº¦
     Â· é»˜è®¤å€¼: 40 (è¾ƒå¯†)
     Â· æ¨èå€¼: 16=ç¨€ç–ï¼Œ32=é€‚ä¸­ï¼Œ40=è¾ƒå¯†ï¼Œ64=å¯†é›†
     Â· è¯´æ˜: å€¼è¶Šå¤§æ£€æµ‹è¶Šå¯†é›†ï¼Œmaskæ•°é‡è¶Šå¤š
   
   - SAM_PRED_IOU_THRESH: é¢„æµ‹IOUé˜ˆå€¼
     Â· é»˜è®¤å€¼: 0.82
     Â· æ¨èå€¼: 0.8-0.95
     Â· è¯´æ˜: å€¼è¶Šé«˜è¦æ±‚maskè´¨é‡è¶Šé«˜ï¼Œè¿‡æ»¤æ›´å¤šä½è´¨é‡mask
   
   - SAM_STABILITY_THRESH: ç¨³å®šæ€§é˜ˆå€¼
     Â· é»˜è®¤å€¼: 0.88
     Â· æ¨èå€¼: 0.85-0.95
     Â· è¯´æ˜: å€¼è¶Šé«˜è¿‡æ»¤è¶Šä¸¥æ ¼
   
   - SAM_MIN_AREA: æœ€å°maské¢ç§¯
     Â· é»˜è®¤å€¼: 70 åƒç´ 
     Â· æ¨èå€¼: 50-200
     Â· è¯´æ˜: è¿‡æ»¤å°äºæ­¤é¢ç§¯çš„ç¢ç‰‡mask

6. AREA_TOLERANCE (é¢ç§¯è¿‡æ»¤å®¹å·®)
   - é»˜è®¤å€¼: 0.5 (ä¸­ä½æ•°çš„Â±50%)
   - æ¨èå€¼: 0.3-0.7
   - è¯´æ˜: æ ¹æ®é¢ç§¯ä¸­ä½æ•°è¿‡æ»¤å¼‚å¸¸mask
     Â· 0.5 è¡¨ç¤ºä¿ç•™é¢ç§¯åœ¨ [ä¸­ä½æ•°Ã—0.5, ä¸­ä½æ•°Ã—1.5] èŒƒå›´å†…çš„mask
     Â· å€¼è¶Šå°è¿‡æ»¤è¶Šä¸¥æ ¼ï¼Œè¶Šå¤§è¶Šå®½æ¾

7. BBOX_ALPHA (çŸ©å½¢æ¡†é€æ˜åº¦)
   - é»˜è®¤å€¼: 0.6 (åŠé€æ˜)
   - æ¨èå€¼: 0.5-0.8
   - è¯´æ˜: æ‰€æœ‰çŸ©å½¢æ¡†çš„é€æ˜åº¦
     Â· 0.0 = å®Œå…¨é€æ˜ï¼ˆçœ‹ä¸è§ï¼‰
     Â· 1.0 = å®Œå…¨ä¸é€æ˜ï¼ˆå®å¿ƒï¼‰
     Â· æ‰€æœ‰æ£€æµ‹æ¡†ç»Ÿä¸€ä½¿ç”¨1pxå•åƒç´ å®½ + åŠé€æ˜æ•ˆæœ

ğŸ¯ å·¥ä½œæµç¨‹:
-----------
ç¬¬1æ­¥: DeepLSDæ£€æµ‹åŸå›¾ â†’ å¾—åˆ°æ‰€æœ‰çº¿æ®µ
ç¬¬2æ­¥: ç»˜åˆ¶çº¯çº¿æ®µå›¾ (all_lines_raw.png)
ç¬¬3æ­¥: åˆ†ç¦»æ¨ªçº¿å’Œç«–çº¿ï¼Œåˆ†åˆ«å¤„ç†ï¼š
       - æ¨ªçº¿å›¾ â†’ DeepLSDäºŒæ¬¡æ£€æµ‹ + é•¿åº¦è¿‡æ»¤ â†’ å»é™¤çŸ­å¹²æ‰°çº¿
       - ç«–çº¿å›¾ â†’ DeepLSDäºŒæ¬¡æ£€æµ‹ + ç«¯ç‚¹è¿‡æ»¤ â†’ åªä¿ç•™ç«¯ç‚¹æ¥è¿‘æ¨ªçº¿çš„ç«–çº¿
ç¬¬4æ­¥: ç”Ÿæˆå¹²å‡€çš„çº¿æ®µå›¾ (all_lines.png)
ç¬¬5æ­¥: ä½¿ç”¨SAMæ£€æµ‹ä½œæ–‡æ ¼ â†’ ç”Ÿæˆæ‰€æœ‰å€™é€‰mask
ç¬¬6æ­¥: æŒ‰é¢ç§¯ä¸­ä½æ•°è¿‡æ»¤å¼‚å¸¸mask â†’ å¾—åˆ°ç»ˆç‰ˆæ£€æµ‹æ¡† (final_bboxes.pngï¼Œè“è‰²)
ç¬¬7æ­¥: ä½¿ç”¨SAM box promptåœ¨æ¯ä¸ªä½œæ–‡æ ¼å†…æ£€æµ‹å­—ç¬¦ (char_detection.pngï¼Œçº¢è‰²)
       - æ¯ä¸ªä½œæ–‡æ ¼æ¡†ä½œä¸ºbox promptè¾“å…¥SAM
       - SAMåœ¨æ¡†å†…ç²¾ç¡®åˆ†å‰²å‡ºå­—ç¬¦mask
       - è¿‡æ»¤ç©ºç™½æ ¼å­ï¼ˆæ— å­—ç¬¦çš„ä¸æ˜¾ç¤ºï¼‰
       - ç”¨çº¢è‰²1pxè¾¹æ¡†æ ‡æ³¨å­—ç¬¦è¾¹ç•Œ
ç¬¬8æ­¥: ç”Ÿæˆåˆå¹¶æ£€æµ‹æ¡†å›¾åƒ (combined_detection.png)
       - è“è‰²æ¡† = æ‰€æœ‰ä½œæ–‡æ ¼å¤–æ¡†
       - çº¢è‰²æ¡† = æœ‰å­—ç¬¦çš„å­—ç¬¦æ¡†ï¼ˆå†…æ¡†ï¼‰
       - ç©ºç™½æ ¼å­æ— çº¢è‰²æ¡†

ğŸ’¡ ç«–çº¿ç«¯ç‚¹è¿‡æ»¤åŸç†:
-------------------
- ä½œæ–‡æ ¼çš„å­—æ ¼åˆ†éš”çº¿ï¼ˆçŸ­ç«–çº¿ï¼‰çš„ç‰¹ç‚¹ï¼šä¸Šä¸‹ä¸¤ç«¯éƒ½ä¸æ¨ªçº¿ç›¸äº¤
- å¹²æ‰°ç«–çº¿çš„ç‰¹ç‚¹ï¼šè‡³å°‘æœ‰ä¸€ç«¯æ‚¬ç©ºï¼Œä¸æ¥è¿‘æ¨ªçº¿
- è¿‡æ»¤æ–¹æ³•ï¼šè®¡ç®—ç«–çº¿çš„ä¸Šä¸‹ç«¯ç‚¹åˆ°æ‰€æœ‰æ¨ªçº¿çš„æœ€çŸ­è·ç¦»
- åˆ¤æ–­æ ‡å‡†ï¼šåªä¿ç•™ä¸Šä¸‹ä¸¤ç«¯éƒ½åœ¨é˜ˆå€¼è·ç¦»å†…æ¥è¿‘æ¨ªçº¿çš„ç«–çº¿
"""

import os
import sys
import cv2
import numpy as np
import torch
from pathlib import Path
import json

# å°è¯•å¯¼å…¥PILï¼ˆæ”¯æŒTIFç­‰æ ¼å¼ï¼‰
try:
    from PIL import Image as PILImage
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# å°è¯•å¯¼å…¥SAM
try:
    from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
    SAM_AVAILABLE = True
except ImportError:
    SAM_AVAILABLE = False
    print("âš ï¸ SAMæœªå®‰è£…ï¼Œè·³è¿‡SAMå¤„ç†")

# æ·»åŠ DeepLSDè·¯å¾„åˆ°sys.path
DEEPLSD_PATH = os.path.join(os.path.dirname(__file__), "DeepLSD")
if os.path.exists(DEEPLSD_PATH):
    sys.path.insert(0, DEEPLSD_PATH)
    print(f"âœ… æ·»åŠ DeepLSDè·¯å¾„: {DEEPLSD_PATH}")
else:
    print(f"âš ï¸ DeepLSDè·¯å¾„ä¸å­˜åœ¨: {DEEPLSD_PATH}")
    DEEPLSD_PATH = None

# å°è¯•å¯¼å…¥DeepLSD
DEEPLSD_AVAILABLE = False
try:
    from deeplsd.models.deeplsd_inference import DeepLSD
    DEEPLSD_AVAILABLE = True
    print("âœ… DeepLSDåº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ DeepLSDå¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ’¡ æç¤º: å¯èƒ½éœ€è¦å®‰è£…ä¾èµ–æˆ–æ¨¡å‹æƒé‡æ–‡ä»¶")


def load_deeplsd_model(model_path=None, device='cuda', grad_thresh=3, merge_lines=False):
    """
    åŠ è½½DeepLSDæ¨¡å‹
    
    Args:
        model_path: æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆ.taræ–‡ä»¶ï¼‰
        device: è®¾å¤‡ï¼ˆ'cuda' æˆ– 'cpu'ï¼‰
        grad_thresh: æ¢¯åº¦é˜ˆå€¼ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼ï¼ˆé»˜è®¤3ï¼Œå¯è®¾ç½®5-10å»é™¤æ›´å¤šå¹²æ‰°ï¼‰
        merge_lines: æ˜¯å¦åˆå¹¶ç›¸è¿‘çš„çº¿æ®µ
    
    Returns:
        net: åŠ è½½å¥½çš„æ¨¡å‹
        device: ä½¿ç”¨çš„è®¾å¤‡
    """
    if not DEEPLSD_AVAILABLE:
        raise ImportError("DeepLSDæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨")
    
    # æ£€æŸ¥è®¾å¤‡
    if device == 'cuda' and not torch.cuda.is_available():
        device = 'cpu'
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
    
    device = torch.device(device)
    
    # å¦‚æœæ²¡æœ‰æä¾›æ¨¡å‹è·¯å¾„ï¼Œå°è¯•é»˜è®¤è·¯å¾„
    if model_path is None:
        possible_paths = [
            "DeepLSD/weights/deeplsd_wireframe.tar",
            "DeepLSD/weights/deeplsd_md.tar",
            "DeepLSD-main/weights/deeplsd_wireframe.tar",
            "DeepLSD-main/weights/deeplsd_md.tar",
            "weights/deeplsd_wireframe.tar",
            "weights/deeplsd_md.tar",
        ]
        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                break
        
        if model_path is None:
            raise FileNotFoundError(
                "æœªæ‰¾åˆ°DeepLSDæ¨¡å‹æƒé‡æ–‡ä»¶ã€‚\n"
                "è¯·ä¸‹è½½æ¨¡å‹åˆ°ä»¥ä¸‹ä½ç½®ä¹‹ä¸€ï¼š\n"
                "  - DeepLSD/weights/deeplsd_md.tar (æ¨è)\n"
                "  - DeepLSD/weights/deeplsd_wireframe.tar\n"
                "\nä¸‹è½½åœ°å€: https://cvg-data.inf.ethz.ch/DeepLSD/"
            )
    
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    
    # æ¨¡å‹é…ç½®
    conf = {
        'detect_lines': True,
        'line_detection_params': {
            'merge': merge_lines,  # æ˜¯å¦åˆå¹¶ç›¸è¿‘çš„çº¿
            'filtering': True,  # è¿‡æ»¤å¼‚å¸¸çº¿
            'grad_thresh': grad_thresh,  # æ¢¯åº¦é˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼‰
            'grad_nfa': True,  # ä½¿ç”¨NFAè¯„åˆ†
        }
    }
    
    # åŠ è½½æ¨¡å‹
    ckpt = torch.load(str(model_path), map_location='cuda',weights_only=False)
    net = DeepLSD(conf)
    net.load_state_dict(ckpt['model'])
    net = net.to(device).eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (grad_thresh={grad_thresh}, merge={merge_lines})")
    return net, device


def detect_lines_deeplsd(image_path, model, device, min_length=0, score_thresh=0.0, is_second_pass=False):
    """
    ä½¿ç”¨DeepLSDæ£€æµ‹çº¿æ®µ
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        model: åŠ è½½å¥½çš„DeepLSDæ¨¡å‹
        device: è®¾å¤‡
        min_length: æœ€å°çº¿æ®µé•¿åº¦ï¼ˆåƒç´ ï¼‰ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶
        score_thresh: çº¿æ®µç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶
        is_second_pass: æ˜¯å¦ä¸ºäºŒæ¬¡æ£€æµ‹ï¼ˆç”¨äºçº¯çº¿æ®µå›¾ï¼Œä¼šä½¿ç”¨æ›´ä¸¥æ ¼çš„å‚æ•°ï¼‰
    
    Returns:
        lines: æ£€æµ‹åˆ°çš„çº¿æ®µï¼Œæ ¼å¼ä¸º numpy array (N, 2, 2)
               æ¯ä¸ªçº¿æ®µæ˜¯ [[x1, y1], [x2, y2]]
    """
    # è¯»å–å›¾åƒï¼ˆæ”¯æŒpng/tifç­‰æ ¼å¼ï¼‰
    img = cv2.imread(image_path)
    
    if img is None:
        # OpenCVåŠ è½½å¤±è´¥ï¼Œå°è¯•PILï¼ˆæ”¯æŒæ›´å¤šæ ¼å¼å¦‚16ä½TIFï¼‰
        if PIL_AVAILABLE:
            try:
                if not is_second_pass:
                    print(f"      OpenCVåŠ è½½å¤±è´¥ï¼Œå°è¯•PIL...")
                pil_image = PILImage.open(image_path)
                if not is_second_pass:
                    print(f"      PILæ¨¡å¼: {pil_image.mode}, å°ºå¯¸: {pil_image.size}")
                
                # è½¬æ¢ä¸ºRGB
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
                
                img = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
                if not is_second_pass:
                    print(f"      âœ“ PILåŠ è½½æˆåŠŸ")
            except Exception as e:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}, é”™è¯¯: {e}")
        else:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
    
    # è½¬æ¢ä¸ºRGBç°åº¦å›¾
    if len(img.shape) == 3:
        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray_img = img
    
    if not is_second_pass:
        print(f"ğŸ–¼ï¸  å›¾åƒå°ºå¯¸: {gray_img.shape[1]} x {gray_img.shape[0]}")
    
    # å‡†å¤‡è¾“å…¥
    img_tensor = torch.tensor(gray_img, dtype=torch.float, device=device)[None, None] / 255.
    
    # æ£€æµ‹çº¿æ®µ
    if is_second_pass:
        print(f"      ğŸ” å¼€å§‹äºŒæ¬¡æ£€æµ‹ï¼ˆä½¿ç”¨ä¸¥æ ¼å‚æ•°ï¼‰...")
    else:
        print("ğŸ” å¼€å§‹æ£€æµ‹çº¿æ®µ...")
    
    with torch.no_grad():
        inputs = {'image': img_tensor}
        outputs = model(inputs)
        pred_lines = outputs['lines'][0]  # (N, 2, 2)
    
    # è¿‡æ»¤çº¿æ®µï¼ˆæ ¹æ®é•¿åº¦å’Œç½®ä¿¡åº¦ï¼‰
    if min_length > 0 or score_thresh > 0:
        filtered_lines = []
        for i, line in enumerate(pred_lines):
            # è®¡ç®—çº¿æ®µé•¿åº¦
            pt1, pt2 = line[0], line[1]
            length = np.sqrt((pt2[0] - pt1[0])**2 + (pt2[1] - pt1[1])**2)
            
            # è·å–çº¿æ®µå¾—åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
            score = outputs.get('line_scores', [1.0] * len(pred_lines))[i] if 'line_scores' in outputs else 1.0
            
            # åº”ç”¨è¿‡æ»¤æ¡ä»¶
            if length >= min_length and score >= score_thresh:
                filtered_lines.append(line)
        
        pred_lines = np.array(filtered_lines) if len(filtered_lines) > 0 else np.array([]).reshape(0, 2, 2)
        
        if is_second_pass:
            print(f"      ğŸ“Š äºŒæ¬¡æ£€æµ‹ç»“æœ: {len(pred_lines)} æ¡çº¿æ®µï¼ˆè¿‡æ»¤åï¼‰")
        else:
            print(f"âœ… æ£€æµ‹åˆ° {len(pred_lines)} æ¡çº¿æ®µï¼ˆè¿‡æ»¤åï¼‰")
    else:
        if is_second_pass:
            print(f"      ğŸ“Š äºŒæ¬¡æ£€æµ‹ç»“æœ: {len(pred_lines)} æ¡çº¿æ®µ")
        else:
            print(f"âœ… æ£€æµ‹åˆ° {len(pred_lines)} æ¡çº¿æ®µ")
    
    return pred_lines, gray_img.shape


def convert_lines_format(lines):
    """
    å°†DeepLSDçš„è¾“å‡ºæ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    
    Args:
        lines: DeepLSDè¾“å‡º (N, 2, 2)ï¼Œæ¯ä¸ªçº¿æ®µæ˜¯ [[x1, y1], [x2, y2]]
    
    Returns:
        lines_standard: æ ‡å‡†æ ¼å¼åˆ—è¡¨ [(x1, y1, x2, y2), ...]
    """
    lines_standard = []
    for line in lines:
        # line shape: (2, 2) -> [[x1, y1], [x2, y2]]
        pt1 = line[0]  # [x1, y1]
        pt2 = line[1]  # [x2, y2]
        lines_standard.append((float(pt1[0]), float(pt1[1]), 
                               float(pt2[0]), float(pt2[1])))
    return lines_standard


def filter_horizontal_vertical(lines_standard, angle_threshold=15):
    """
    å°†çº¿æ®µåˆ†ç±»ä¸ºæ¨ªçº¿å’Œç«–çº¿
    
    Args:
        lines_standard: çº¿æ®µåˆ—è¡¨ [(x1, y1, x2, y2), ...]
        angle_threshold: è§’åº¦é˜ˆå€¼ï¼ˆåº¦ï¼‰ï¼Œé»˜è®¤15åº¦
    
    Returns:
        horizontal_lines: æ¨ªçº¿åˆ—è¡¨
        vertical_lines: ç«–çº¿åˆ—è¡¨
        other_lines: å…¶ä»–æ–¹å‘çš„çº¿æ®µ
    """
    horizontal_lines = []
    vertical_lines = []
    other_lines = []
    
    for x1, y1, x2, y2 in lines_standard:
        # è®¡ç®—è§’åº¦
        dx = x2 - x1
        dy = y2 - y1
        
        # é¿å…é™¤é›¶
        if abs(dx) < 1e-6 and abs(dy) < 1e-6:
            continue
        
        # è®¡ç®—è§’åº¦ï¼ˆå¼§åº¦è½¬åº¦ï¼‰
        angle = np.abs(np.arctan2(dy, dx) * 180 / np.pi)
        
        # å½’ä¸€åŒ–è§’åº¦åˆ°0-90åº¦
        if angle > 90:
            angle = 180 - angle
        
        # åˆ†ç±»
        if angle < angle_threshold:  # æ¥è¿‘æ°´å¹³
            horizontal_lines.append((x1, y1, x2, y2))
        elif angle > (90 - angle_threshold):  # æ¥è¿‘å‚ç›´
            vertical_lines.append((x1, y1, x2, y2))
        else:
            other_lines.append((x1, y1, x2, y2))
    
    return horizontal_lines, vertical_lines, other_lines


def visualize_lines(image_path, horizontal_lines, vertical_lines, output_path):
    """
    å¯è§†åŒ–æ£€æµ‹åˆ°çš„æ¨ªçº¿å’Œç«–çº¿
    
    Args:
        image_path: åŸå§‹å›¾åƒè·¯å¾„
        horizontal_lines: æ¨ªçº¿åˆ—è¡¨
        vertical_lines: ç«–çº¿åˆ—è¡¨
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„
    """
    img = cv2.imread(image_path)
    if img is None:
        print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return
    
    # ç»˜åˆ¶æ¨ªçº¿ï¼ˆçº¢è‰²ï¼‰
    for x1, y1, x2, y2 in horizontal_lines:
        cv2.line(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)
    
    # ç»˜åˆ¶ç«–çº¿ï¼ˆç»¿è‰²ï¼‰
    for x1, y1, x2, y2 in vertical_lines:
        cv2.line(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
    
    cv2.imwrite(output_path, img)
    print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")


def save_results(txt_path, horizontal_lines, vertical_lines, image_name):
    """ä¿å­˜æ£€æµ‹ç»“æœåˆ°æ–‡æœ¬æ–‡ä»¶"""
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(f"# DeepLSDçº¿æ®µæ£€æµ‹ç»“æœ - {image_name}\n")
        f.write(f"# æ£€æµ‹æ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write(f"# æ¨ªçº¿æ•°é‡: {len(horizontal_lines)}\n")
        f.write("# æ ¼å¼: line_id, x1, y1, x2, y2\n")
        for i, (x1, y1, x2, y2) in enumerate(horizontal_lines):
            f.write(f"horizontal_{i:04d}: {x1:.2f}, {y1:.2f}, {x2:.2f}, {y2:.2f}\n")
        
        f.write(f"\n# ç«–çº¿æ•°é‡: {len(vertical_lines)}\n")
        f.write("# æ ¼å¼: line_id, x1, y1, x2, y2\n")
        for i, (x1, y1, x2, y2) in enumerate(vertical_lines):
            f.write(f"vertical_{i:04d}: {x1:.2f}, {y1:.2f}, {x2:.2f}, {y2:.2f}\n")
    
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {txt_path}")


def filter_grid_lines(lines, line_type, img_shape):
    """
    è¿‡æ»¤ç½‘æ ¼çº¿ï¼šä¿ç•™é•¿çš„ç½‘æ ¼çº¿ï¼Œå»æ‰æ–¹æ ¼å†…çš„çŸ­å¹²æ‰°çº¿å’Œæ–œçº¿
    
    Args:
        lines: çº¿æ®µåˆ—è¡¨ [(x1, y1, x2, y2), ...]
        line_type: 'horizontal' æˆ– 'vertical'
        img_shape: å›¾åƒå°ºå¯¸ (height, width)
    
    Returns:
        filtered_lines: è¿‡æ»¤åçš„çº¿æ®µåˆ—è¡¨
    """
    if len(lines) == 0:
        return []
    
    img_h, img_w = img_shape[:2]
    
    # è®¡ç®—æ¯æ¡çº¿æ®µçš„é•¿åº¦å’Œè§’åº¦
    filtered_lines = []
    line_lengths = []
    
    for x1, y1, x2, y2 in lines:
        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
        if length == 0:
            continue
        
        # è®¡ç®—è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³æ–¹å‘çš„å¤¹è§’ï¼‰
        dx = x2 - x1
        dy = y2 - y1
        angle = np.abs(np.arctan2(dy, dx) * 180 / np.pi)
        
        # è§„èŒƒè§’åº¦åˆ°0-90åº¦
        if angle > 90:
            angle = 180 - angle
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæ–œçº¿ï¼ˆè§’åº¦ä¸åœ¨æ¥è¿‘0åº¦æˆ–90åº¦çš„èŒƒå›´å†…ï¼‰
        # æ¨ªçº¿ï¼šè§’åº¦åº”è¯¥æ¥è¿‘0åº¦ï¼ˆ0-10åº¦æˆ–170-180åº¦ï¼‰
        # ç«–çº¿ï¼šè§’åº¦åº”è¯¥æ¥è¿‘90åº¦ï¼ˆ80-100åº¦ï¼‰
        is_valid_angle = False
        if line_type == 'horizontal':
            # æ¨ªçº¿ï¼šè§’åº¦æ¥è¿‘0åº¦æˆ–180åº¦ï¼ˆè§„èŒƒå0-10åº¦æˆ–80-90åº¦ï¼‰
            is_valid_angle = angle <= 10 or angle >= 85
        else:  # vertical
            # ç«–çº¿ï¼šè§’åº¦æ¥è¿‘90åº¦ï¼ˆè§„èŒƒå80-90åº¦ï¼‰
            is_valid_angle = angle >= 80
        
        if is_valid_angle:
            filtered_lines.append((x1, y1, x2, y2))
            line_lengths.append(length)
    
    if len(line_lengths) == 0:
        return []
    
    line_lengths = np.array(line_lengths)
    
    # è®¡ç®—é•¿åº¦ç»Ÿè®¡
    median_length = np.median(line_lengths)
    
    # è®¾ç½®æœ€å°é•¿åº¦é˜ˆå€¼ä¸ºä¸­ä½æ•°çš„50%
    min_length = median_length * 0.5
    
    print(f"      ä¸­ä½æ•°é•¿åº¦: {median_length:.1f}px, æœ€å°é˜ˆå€¼: {min_length:.1f}px ({'æ¨ªçº¿' if line_type == 'horizontal' else 'ç«–çº¿'})")
    
    # å†æ¬¡ç­›é€‰ï¼šä¿ç•™é•¿åº¦è¶³å¤Ÿé•¿çš„çº¿æ®µ
    final_filtered_lines = []
    for i, (x1, y1, x2, y2) in enumerate(filtered_lines):
        length = line_lengths[i]
        if length >= min_length:
            final_filtered_lines.append((x1, y1, x2, y2))
    
    return final_filtered_lines


def is_point_near_lines(point, lines, threshold=5):
    """
    æ£€æŸ¥ç‚¹æ˜¯å¦æ¥è¿‘ä»»ä½•ä¸€æ¡çº¿
    
    Args:
        point: (x, y) åæ ‡
        lines: çº¿æ®µåˆ—è¡¨ [(x1, y1, x2, y2), ...]
        threshold: è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
    
    Returns:
        bool: Trueå¦‚æœç‚¹æ¥è¿‘ä»»ä½•ä¸€æ¡çº¿
    """
    px, py = point
    
    for x1, y1, x2, y2 in lines:
        # è®¡ç®—ç‚¹åˆ°çº¿æ®µçš„æœ€çŸ­è·ç¦»
        # ä½¿ç”¨å‘é‡æŠ•å½±æ–¹æ³•
        line_vec = np.array([x2 - x1, y2 - y1])
        point_vec = np.array([px - x1, py - y1])
        
        line_len_sq = line_vec[0]**2 + line_vec[1]**2
        if line_len_sq == 0:
            # çº¿æ®µé€€åŒ–ä¸ºç‚¹
            dist = np.sqrt((px - x1)**2 + (py - y1)**2)
        else:
            # æŠ•å½±å‚æ•°t (0<=t<=1è¡¨ç¤ºæŠ•å½±ç‚¹åœ¨çº¿æ®µä¸Š)
            t = max(0, min(1, np.dot(point_vec, line_vec) / line_len_sq))
            # æŠ•å½±ç‚¹åæ ‡
            proj_x = x1 + t * line_vec[0]
            proj_y = y1 + t * line_vec[1]
            # ç‚¹åˆ°æŠ•å½±ç‚¹çš„è·ç¦»
            dist = np.sqrt((px - proj_x)**2 + (py - proj_y)**2)
        
        if dist <= threshold:
            return True
    
    return False


def filter_vertical_lines_by_endpoints(vertical_lines, horizontal_lines, distance_threshold=10):
    """
    æ ¹æ®ç«¯ç‚¹æ˜¯å¦æ¥è¿‘å…¶ä»–çº¿æ¥è¿‡æ»¤ç«–çº¿
    åªä¿ç•™ä¸Šä¸‹ä¸¤ç«¯éƒ½æ¥è¿‘æ¨ªçº¿çš„ç«–çº¿ï¼ˆä½œæ–‡æ ¼çš„å­—æ ¼åˆ†éš”çº¿ï¼‰
    
    Args:
        vertical_lines: ç«–çº¿åˆ—è¡¨ [(x1, y1, x2, y2), ...]
        horizontal_lines: æ¨ªçº¿åˆ—è¡¨ [(x1, y1, x2, y2), ...]
        distance_threshold: ç«¯ç‚¹åˆ°çº¿çš„è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
    
    Returns:
        filtered_lines: è¿‡æ»¤åçš„ç«–çº¿åˆ—è¡¨
    """
    if len(vertical_lines) == 0:
        return []
    
    if len(horizontal_lines) == 0:
        print(f"      âš ï¸ æ²¡æœ‰æ¨ªçº¿ï¼Œæ— æ³•è¿‡æ»¤ç«–çº¿ç«¯ç‚¹")
        return vertical_lines
    
    filtered_lines = []
    
    for x1, y1, x2, y2 in vertical_lines:
        # ç¡®ä¿y1æ˜¯ä¸Šç«¯ç‚¹ï¼Œy2æ˜¯ä¸‹ç«¯ç‚¹
        if y1 > y2:
            y1, y2 = y2, y1
        
        # æ£€æŸ¥ä¸Šç«¯ç‚¹å’Œä¸‹ç«¯ç‚¹æ˜¯å¦éƒ½æ¥è¿‘æ¨ªçº¿
        top_point = (x1, y1)
        bottom_point = (x2, y2)
        
        top_near = is_point_near_lines(top_point, horizontal_lines, distance_threshold)
        bottom_near = is_point_near_lines(bottom_point, horizontal_lines, distance_threshold)
        
        # åªä¿ç•™ä¸Šä¸‹ä¸¤ç«¯éƒ½æ¥è¿‘æ¨ªçº¿çš„ç«–çº¿
        if top_near and bottom_near:
            filtered_lines.append((x1, y1, x2, y2))
    
    print(f"      ğŸ“Š ç«¯ç‚¹è¿‡æ»¤: {len(vertical_lines)} -> {len(filtered_lines)} (ä¿ç•™ä¸Šä¸‹ç«¯éƒ½æ¥è¿‘æ¨ªçº¿çš„)")
    
    return filtered_lines


def filter_vertical_lines(vertical_lines, img_shape):
    """
    ç­›é€‰ç«–çº¿ï¼šä¿ç•™é•¿åº¦å‡ ä¹ç›¸ç­‰çš„çŸ­ç«–çº¿å’Œç‰¹é•¿çš„ç«–çº¿
    
    Args:
        vertical_lines: ç«–çº¿åˆ—è¡¨ [(x1, y1, x2, y2), ...]
        img_shape: å›¾åƒå°ºå¯¸ (height, width)
    
    Returns:
        (short_lines, long_lines): (çŸ­ç«–çº¿åˆ—è¡¨, ç‰¹é•¿ç«–çº¿åˆ—è¡¨)
    """
    if len(vertical_lines) == 0:
        return [], []
    
    img_h, img_w = img_shape[:2]
    
    # è®¡ç®—æ¯æ¡ç«–çº¿çš„é•¿åº¦
    line_lengths = []
    for x1, y1, x2, y2 in vertical_lines:
        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
        line_lengths.append(length)
    
    line_lengths = np.array(line_lengths)
    
    # æ‰¾å‡ºé•¿åº¦å‡ ä¹ç›¸ç­‰çš„çŸ­ç«–çº¿
    # ä½¿ç”¨ä¸­ä½æ•°é•¿åº¦ä½œä¸ºåŸºå‡†
    median_length = np.median(line_lengths)
    print(f"   ğŸ“ ç«–çº¿é•¿åº¦ç»Ÿè®¡: ä¸­ä½æ•°={median_length:.1f}px, èŒƒå›´=[{line_lengths.min():.1f}, {line_lengths.max():.1f}]px")
    
    # ç­›é€‰å‡ºé•¿åº¦æ¥è¿‘ä¸­ä½æ•°çš„çŸ­ç«–çº¿ï¼ˆÂ±30%ï¼‰å’Œç‰¹é•¿ç«–çº¿ï¼ˆâ‰¥2å€ä¸­ä½æ•°ï¼‰
    short_lines = []
    long_lines = []
    
    for i, (x1, y1, x2, y2) in enumerate(vertical_lines):
        length = line_lengths[i]
        # çŸ­ç«–çº¿ï¼šé•¿åº¦åœ¨0.7-1.3å€ä¸­ä½æ•°ä¹‹é—´
        if median_length * 0.7 <= length <= median_length * 1.3:
            short_lines.append((x1, y1, x2, y2))
        # ç‰¹é•¿ç«–çº¿ï¼šé•¿åº¦å¤§äºä¸­ä½æ•°çš„2å€ï¼ˆå¯èƒ½æ˜¯é¡µé¢è¾¹ç¼˜çº¿ï¼‰
        elif length >= median_length * 2.0:
            long_lines.append((x1, y1, x2, y2))
    
    print(f"   âœ… çŸ­ç«–çº¿: {len(short_lines)} æ¡ (é•¿åº¦â‰ˆ{median_length:.1f}px)")
    print(f"   âœ… ç‰¹é•¿ç«–çº¿: {len(long_lines)} æ¡ (é•¿åº¦â‰¥{median_length*2.0:.1f}px)")
    
    # æŒ‰Xåæ ‡æ’åº
    short_lines.sort(key=lambda line: (line[0] + line[2]) / 2)
    long_lines.sort(key=lambda line: (line[0] + line[2]) / 2)
    
    return short_lines, long_lines




def load_sam_model(checkpoint_path=None, model_type="vit_h", device="cuda"):
    """
    åŠ è½½SAMæ¨¡å‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼Œåªåœ¨éœ€è¦æ—¶åŠ è½½ä¸€æ¬¡ï¼‰
    """
    if not SAM_AVAILABLE:
        raise ImportError("SAMæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šcheckpointè·¯å¾„ï¼Œå°è¯•è‡ªåŠ¨æŸ¥æ‰¾
    if checkpoint_path is None:
        possible_paths = [
            "sam_vit_h_4b8939.pth",
            "sam_vit_l_0b3195.pth",
            "sam_vit_b_01ec64.pth",
        ]
        for path in possible_paths:
            if os.path.exists(path):
                checkpoint_path = path
                if "vit_h" in path:
                    model_type = "vit_h"
                elif "vit_l" in path:
                    model_type = "vit_l"
                elif "vit_b" in path:
                    model_type = "vit_b"
                break
        
        if checkpoint_path is None:
            raise FileNotFoundError("æ‰¾ä¸åˆ°SAMæ¨¡å‹æ–‡ä»¶ï¼Œè¯·ä¸‹è½½å¹¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•")
    
    # æ£€æŸ¥è®¾å¤‡
    if device == "cuda" and not torch.cuda.is_available():
        device = "cpu"
        print("   âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
    
    sam = sam_model_registry[model_type](checkpoint=checkpoint_path)
    sam.to(device=device)
    return sam, device


def process_char_detection_with_sam(original_image_path, grid_bboxes, output_dir, image_name, bbox_alpha=0.6):
    """
    ä½¿ç”¨SAMçš„box promptæ¨¡å¼åœ¨æ¯ä¸ªä½œæ–‡æ ¼æ¡†å†…æ£€æµ‹å­—ç¬¦
    
    Args:
        original_image_path: åŸå›¾è·¯å¾„
        grid_bboxes: ä½œæ–‡æ ¼æ£€æµ‹æ¡†åˆ—è¡¨ [{"x": x, "y": y, "width": w, "height": h}, ...]
        output_dir: è¾“å‡ºç›®å½•
        image_name: å›¾åƒåç§°
        bbox_alpha: çŸ©å½¢æ¡†é€æ˜åº¦ï¼ˆ0.0-1.0ï¼‰
    
    Returns:
        char_results: å­—ç¬¦æ£€æµ‹ç»“æœåˆ—è¡¨
    """
    if not SAM_AVAILABLE:
        print(f"   âš ï¸ SAMæœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œå­—ç¬¦æ£€æµ‹")
        return []
    
    # åŠ è½½SAMæ¨¡å‹
    try:
        sam, device = load_sam_model()
    except Exception as e:
        print(f"   âŒ SAMæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return []
    
    # è¯»å–åŸå›¾
    image = cv2.imread(original_image_path)
    if image is None:
        print(f"   âŒ æ— æ³•è¯»å–å›¾åƒ: {original_image_path}")
        return []
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # åˆ›å»ºSAMé¢„æµ‹å™¨ï¼ˆç”¨äºbox promptï¼‰
    from segment_anything import SamPredictor
    predictor = SamPredictor(sam)
    predictor.set_image(image_rgb)
    
    print(f"   ğŸ” å¼€å§‹å­—ç¬¦æ£€æµ‹ï¼ˆå…±{len(grid_bboxes)}ä¸ªä½œæ–‡æ ¼ï¼‰...")
    
    char_results = []
    # åˆ›å»ºoverlayå±‚ç”¨äºåŠé€æ˜ç»˜åˆ¶
    overlay = image.copy()
    
    for grid_idx, grid_bbox in enumerate(grid_bboxes):
        grid_x = grid_bbox['x']
        grid_y = grid_bbox['y']
        grid_w = grid_bbox['width']
        grid_h = grid_bbox['height']
        
        # å‡†å¤‡box promptï¼ˆæ ¼å¼ï¼š[x1, y1, x2, y2]ï¼‰
        box_prompt = np.array([grid_x, grid_y, grid_x + grid_w, grid_y + grid_h])
        
        # ä½¿ç”¨SAMé¢„æµ‹
        masks, scores, logits = predictor.predict(
            point_coords=None,
            point_labels=None,
            box=box_prompt[None, :],  # shape: (1, 4)
            multimask_output=False  # åªè¾“å‡ºä¸€ä¸ªæœ€ä½³mask
        )
        
        # å–å¾—åˆ†æœ€é«˜çš„mask
        if len(masks) > 0 and len(scores) > 0:
            best_idx = np.argmax(scores)
            mask = masks[best_idx]  # shape: (H, W)
            score = scores[best_idx]
            
            # ä»maskè®¡ç®—å­—ç¬¦çš„è¾¹ç•Œæ¡†
            # æ‰¾åˆ°maskä¸­æ‰€æœ‰Trueçš„ç‚¹
            points = np.argwhere(mask)
            
            if len(points) > 0:
                # è®¡ç®—æœ€å°å¤–æ¥çŸ©å½¢
                y_coords = points[:, 0]
                x_coords = points[:, 1]
                
                char_x1 = int(np.min(x_coords))
                char_y1 = int(np.min(y_coords))
                char_x2 = int(np.max(x_coords))
                char_y2 = int(np.max(y_coords))
                
                char_w = char_x2 - char_x1
                char_h = char_y2 - char_y1
                
                # è®¡ç®—å­—ç¬¦maskçš„å®é™…é¢ç§¯
                char_area = np.sum(mask)
                
                # è¿‡æ»¤ç©ºç™½æ ¼å­ï¼šå¦‚æœå­—ç¬¦é¢ç§¯å¤ªå°æˆ–å°ºå¯¸å¤ªå°ï¼Œè®¤ä¸ºæ˜¯ç©ºç™½
                # é˜ˆå€¼ï¼šé¢ç§¯è‡³å°‘10åƒç´ ï¼Œä¸”å®½é«˜è‡³å°‘3åƒç´ 
                min_char_area = 10
                min_char_size = 3
                
                if char_area >= min_char_area and char_w >= min_char_size and char_h >= min_char_size:
                    # ä¿å­˜å­—ç¬¦æ£€æµ‹ç»“æœ
                    char_results.append({
                        "grid_id": grid_idx,
                        "grid_bbox": {
                            "x": float(grid_x),
                            "y": float(grid_y),
                            "width": float(grid_w),
                            "height": float(grid_h)
                        },
                        "char_bbox": {
                            "x": char_x1,
                            "y": char_y1,
                            "width": char_w,
                            "height": char_h
                        },
                        "char_area": int(char_area),
                        "confidence": float(score)
                    })
                    
                    # åœ¨overlayå±‚ä¸Šç»˜åˆ¶çº¢è‰²1pxè¾¹æ¡†
                    cv2.rectangle(overlay, (char_x1, char_y1), (char_x2, char_y2), (0, 0, 255), 1)
    
    # å åŠ åŠé€æ˜æ•ˆæœ
    vis_img = cv2.addWeighted(overlay, bbox_alpha, image, 1 - bbox_alpha, 0)
    
    print(f"   âœ… å­—ç¬¦æ£€æµ‹å®Œæˆï¼Œæ£€æµ‹åˆ° {len(char_results)} ä¸ªå­—ç¬¦ï¼ˆå·²è¿‡æ»¤ç©ºç™½æ ¼å­ï¼‰")
    
    # ä¿å­˜å­—ç¬¦æ£€æµ‹å¯è§†åŒ–
    char_vis_path = os.path.join(output_dir, f"{image_name}_char_detection.png")
    cv2.imwrite(char_vis_path, vis_img)
    print(f"   âœ… å­—ç¬¦æ£€æµ‹æ¡†å·²ä¿å­˜: {char_vis_path} (çº¢è‰²1pxåŠé€æ˜ï¼Œä»…æ˜¾ç¤ºæœ‰å­—ç¬¦çš„æ ¼å­)")
    
    # ä¿å­˜å­—ç¬¦æ£€æµ‹JSON
    char_json_path = os.path.join(output_dir, f"{image_name}_char_detection.json")
    char_json_data = {
        "image": image_name,
        "total_grids": len(grid_bboxes),
        "detected_chars": len(char_results),
        "method": "SAM_box_prompt",
        "chars": char_results
    }
    
    with open(char_json_path, 'w', encoding='utf-8') as f:
        json.dump(char_json_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… å­—ç¬¦æ£€æµ‹JSONå·²ä¿å­˜: {char_json_path}")
    
    return char_results


def filter_masks_by_area(masks, area_tolerance=0.5):
    """
    æ ¹æ®é¢ç§¯ä¸­ä½æ•°è¿‡æ»¤æ‰å¼‚å¸¸å¤§å°çš„mask
    
    Args:
        masks: SAMç”Ÿæˆçš„masksåˆ—è¡¨
        area_tolerance: é¢ç§¯å®¹å·®èŒƒå›´ï¼ˆç›¸å¯¹ä¸­ä½æ•°çš„æ¯”ä¾‹ï¼‰ï¼Œé»˜è®¤0.5ï¼ˆå³ä¸­ä½æ•°çš„50%-150%ï¼‰
    
    Returns:
        filtered_masks: è¿‡æ»¤åçš„masksåˆ—è¡¨
    """
    if len(masks) == 0:
        return []
    
    # ç»Ÿè®¡æ‰€æœ‰maskçš„é¢ç§¯
    areas = [m['area'] for m in masks]
    
    if len(areas) == 0:
        return []
    
    # è®¡ç®—é¢ç§¯ä¸­ä½æ•°
    median_area = np.median(areas)
    
    # è®¡ç®—é¢ç§¯èŒƒå›´
    area_min = median_area * (1 - area_tolerance)
    area_max = median_area * (1 + area_tolerance)
    
    print(f"   ğŸ“Š é¢ç§¯ç»Ÿè®¡: ä¸­ä½æ•°={median_area:.0f}, èŒƒå›´=[{min(areas):.0f}, {max(areas):.0f}]")
    print(f"   ğŸ“Š è¿‡æ»¤èŒƒå›´: [{area_min:.0f}, {area_max:.0f}] (ä¸­ä½æ•°Â±{area_tolerance*100:.0f}%)")
    
    # è¿‡æ»¤mask
    filtered_masks = []
    for m in masks:
        area = m['area']
        if area_min <= area <= area_max:
            filtered_masks.append(m)
    
    print(f"   âœ… é¢ç§¯è¿‡æ»¤: {len(masks)} -> {len(filtered_masks)} ä¸ªmask")
    
    return filtered_masks


def filter_grid_masks(masks, image_name, target_rows=20, target_cols=16):
    """
    ç­›é€‰å‡ºè§„åˆ™çš„ç½‘æ ¼maskï¼ˆ20Ã—16æˆ–17Ã—16ï¼‰
    åŸºäºé¢ç§¯ç»Ÿè®¡è§„å¾‹ï¼šä½œæ–‡æ ¼é¢ç§¯åŸºæœ¬ä¸€è‡´ï¼Œæ‰¾åˆ°é¢ç§¯æœ€é›†ä¸­çš„åŒºåŸŸ
    
    Args:
        masks: SAMç”Ÿæˆçš„masksåˆ—è¡¨
        image_name: å›¾åƒåç§°ï¼ˆç”¨äºåˆ¤æ–­ç±»å‹ï¼‰
        target_rows: ç›®æ ‡è¡Œæ•°ï¼ˆ20æˆ–17ï¼‰
        target_cols: ç›®æ ‡åˆ—æ•°ï¼ˆ16ï¼‰
    
    Returns:
        filtered_masks: ç­›é€‰åçš„masksåˆ—è¡¨
    """
    if len(masks) == 0:
        return []
    
    # ç»Ÿè®¡æ‰€æœ‰maskçš„é¢ç§¯
    areas = [m['area'] for m in masks]
    
    if len(areas) == 0:
        return []
    
    # è¿‡æ»¤æ‰å¼‚å¸¸å¤§çš„é¢ç§¯ï¼ˆå¯èƒ½æ˜¯å¤šä¸ªæ–¹æ ¼åˆå¹¶ï¼‰
    max_reasonable_area = np.percentile(areas, 95)  # 95åˆ†ä½æ•°ä½œä¸ºæœ€å¤§åˆç†é¢ç§¯
    reasonable_masks = [m for m in masks if m['area'] <= max_reasonable_area]
    reasonable_areas = [m['area'] for m in reasonable_masks]
    
    if len(reasonable_areas) == 0:
        return []
    
    print(f"   ğŸ“Š é¢ç§¯ç»Ÿè®¡: èŒƒå›´=[{min(areas)}, {max(areas)}], ä¸­ä½æ•°={np.median(areas):.0f}")
    print(f"   ğŸ“Š åˆç†é¢ç§¯èŒƒå›´: [0, {max_reasonable_area:.0f}], å€™é€‰mask: {len(reasonable_masks)}")
    
    # æ‰¾åˆ°é¢ç§¯æœ€é›†ä¸­çš„åŒºåŸŸï¼ˆä½œæ–‡æ ¼åº”è¯¥é¢ç§¯åŸºæœ¬ä¸€è‡´ï¼‰
    # ä½¿ç”¨ç›´æ–¹å›¾æ‰¾åˆ°å³°å€¼
    hist, bins = np.histogram(reasonable_areas, bins=100)
    peak_idx = np.argmax(hist)
    peak_area = (bins[peak_idx] + bins[peak_idx + 1]) / 2
    
    # è®¡ç®—é¢ç§¯çš„ä¸­ä½æ•°å’Œå››åˆ†ä½è·
    median_area = np.median(reasonable_areas)
    q1_area = np.percentile(reasonable_areas, 25)
    q3_area = np.percentile(reasonable_areas, 75)
    iqr_area = q3_area - q1_area
    
    # ä½¿ç”¨IQRæ–¹æ³•æ‰¾åˆ°é›†ä¸­åŒºåŸŸï¼šQ1åˆ°Q3ä¹‹é—´
    # ä½†ç¨å¾®æ‰©å±•ä¸€ç‚¹ï¼Œä¿ç•™æ›´å¤šå€™é€‰
    area_lower = max(q1_area - 0.5 * iqr_area, min(reasonable_areas) * 0.5)
    area_upper = min(q3_area + 0.5 * iqr_area, max(reasonable_areas) * 2)
    
    print(f"   ğŸ“Š é¢ç§¯å³°å€¼: {peak_area:.0f}, ä¸­ä½æ•°={median_area:.0f}, IQR=[{q1_area:.0f}, {q3_area:.0f}]")
    print(f"   ğŸ“Š ä½œæ–‡æ ¼é¢ç§¯èŒƒå›´: [{area_lower:.0f}, {area_upper:.0f}]")
    
    # ç­›é€‰ç¬¦åˆä½œæ–‡æ ¼é¢ç§¯çš„maskï¼ˆæ”¾å®½ç­›é€‰æ¡ä»¶ï¼‰
    candidate_masks = []
    for m in reasonable_masks:
        area = m['area']
        bbox = m['bbox']
        w, h = bbox[2], bbox[3]
        aspect_ratio = w / h if h > 0 else 0
        
        # ç­›é€‰æ¡ä»¶ï¼šé¢ç§¯åœ¨é›†ä¸­èŒƒå›´å†…ï¼Œå®½é«˜æ¯”åˆç†ï¼ˆ0.3-3.0ï¼‰ï¼Œå¹¶ä¸”é¢ç§¯ä¸èƒ½å¤ªå°
        if area >= area_lower and area <= area_upper and area >= 50 and 0.3 <= aspect_ratio <= 3.0:
            candidate_masks.append(m)
    
    print(f"   ğŸ“Š ç¬¦åˆä½œæ–‡æ ¼é¢ç§¯çš„mask: {len(candidate_masks)} ä¸ª")
    
    if len(candidate_masks) == 0:
        print(f"   âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆä½œæ–‡æ ¼é¢ç§¯çš„mask")
        return []
    
    main_masks = candidate_masks
    
    # æŒ‰ä½ç½®æ’åºï¼Œå°è¯•ç»„æˆç½‘æ ¼
    main_masks.sort(key=lambda m: (m['bbox'][1], m['bbox'][0]))  # å…ˆæŒ‰Yï¼Œå†æŒ‰X
    
    # è®¡ç®—maskçš„å¹³å‡å°ºå¯¸ï¼ˆç”¨äºè®¡ç®—é—´è·ï¼‰
    if len(main_masks) > 0:
        sizes = [(m['bbox'][2], m['bbox'][3]) for m in main_masks]
        median_w = np.median([s[0] for s in sizes])
        median_h = np.median([s[1] for s in sizes])
    else:
        median_w = 50
        median_h = 50
    
    # è®¡ç®—å¹³å‡é—´è·
    if len(main_masks) > 1:
        # æŒ‰Yåæ ‡æ’åºï¼Œè®¡ç®—å‚ç›´é—´è·
        y_coords = [m['bbox'][1] + m['bbox'][3]/2 for m in main_masks]
        sorted_y = sorted(y_coords)
        y_spacings = [sorted_y[i+1] - sorted_y[i] 
                     for i in range(len(sorted_y)-1) 
                     if sorted_y[i+1] - sorted_y[i] > 0 and sorted_y[i+1] - sorted_y[i] < median_h * 3]
        row_spacing = np.median(y_spacings) if len(y_spacings) > 0 else median_h * 1.2
        
        # æŒ‰Xåæ ‡æ’åºï¼Œè®¡ç®—æ°´å¹³é—´è·
        x_coords = [m['bbox'][0] + m['bbox'][2]/2 for m in main_masks]
        sorted_x = sorted(x_coords)
        x_spacings = [sorted_x[i+1] - sorted_x[i] 
                     for i in range(len(sorted_x)-1) 
                     if sorted_x[i+1] - sorted_x[i] > 0 and sorted_x[i+1] - sorted_x[i] < median_w * 3]
        col_spacing = np.median(x_spacings) if len(x_spacings) > 0 else median_w * 1.2
    else:
        row_spacing = median_h * 1.2
        col_spacing = median_w * 1.2
    
    # èšç±»è¡Œå’Œåˆ—
    y_coords = [m['bbox'][1] + m['bbox'][3]/2 for m in main_masks]
    x_coords = [m['bbox'][0] + m['bbox'][2]/2 for m in main_masks]
    
    # å¯¹Yåæ ‡èšç±»ï¼ˆè¡Œï¼‰
    from sklearn.cluster import DBSCAN
    y_array = np.array(y_coords).reshape(-1, 1)
    if row_spacing > 0:
        y_eps = float(row_spacing * 0.4)
    else:
        y_eps = float(median_h * 0.3) if median_h > 0 else 10.0
    y_eps = max(y_eps, 2.0)
    y_clustering = DBSCAN(eps=y_eps, min_samples=1).fit(y_array)
    
    # å¯¹Xåæ ‡èšç±»ï¼ˆåˆ—ï¼‰
    x_array = np.array(x_coords).reshape(-1, 1)
    if col_spacing > 0:
        x_eps = float(col_spacing * 0.4)
    else:
        x_eps = float(median_w * 0.3) if median_w > 0 else 10.0
    x_eps = max(x_eps, 2.0)
    x_clustering = DBSCAN(eps=x_eps, min_samples=1).fit(x_array)
    
    # è·å–èšç±»åçš„è¡Œæ•°å’Œåˆ—æ•°
    unique_y_labels = [l for l in np.unique(y_clustering.labels_) if l != -1]
    unique_x_labels = [l for l in np.unique(x_clustering.labels_) if l != -1]
    
    detected_rows = len(unique_y_labels)
    detected_cols = len(unique_x_labels)
    
    print(f"   ğŸ“Š æ£€æµ‹åˆ°: {detected_rows}è¡Œ Ã— {detected_cols}åˆ— (ç›®æ ‡: {target_rows}è¡Œ Ã— {target_cols}åˆ—)")
    
    # è®¡ç®—æ¯è¡Œçš„å¹³å‡Yåæ ‡å’Œæ¯åˆ—çš„å¹³å‡Xåæ ‡
    row_y_means = []
    for label in unique_y_labels:
        row_mask_indices = np.where(y_clustering.labels_ == label)[0]
        if len(row_mask_indices) > 0:
            row_y = np.mean([y_coords[i] for i in row_mask_indices])
            row_y_means.append((label, row_y))
    
    row_y_means.sort(key=lambda x: x[1])
    
    col_x_means = []
    for label in unique_x_labels:
        col_mask_indices = np.where(x_clustering.labels_ == label)[0]
        if len(col_mask_indices) > 0:
            col_x = np.mean([x_coords[i] for i in col_mask_indices])
            col_x_means.append((label, col_x))
    
    col_x_means.sort(key=lambda x: x[1])
    
    # å¦‚æœæ£€æµ‹åˆ°çš„è¡Œåˆ—æ•°ä¸è¶³ï¼Œç›´æ¥æŒ‰ä½ç½®æ’åºé€‰æ‹©
    if detected_rows < target_rows or detected_cols < target_cols:
        print(f"   âš ï¸ æ£€æµ‹åˆ°çš„ç½‘æ ¼ä¸å®Œæ•´ï¼ŒæŒ‰ä½ç½®æ’åºé€‰æ‹©...")
        # æŒ‰ä½ç½®æ’åºï¼Œä¿ç•™æœ€å¤štarget_rows * target_colsä¸ª
        main_masks.sort(key=lambda m: (m['bbox'][1], m['bbox'][0]))
        filtered_masks = main_masks[:target_rows * target_cols]
        print(f"   âœ… ç­›é€‰å: {len(filtered_masks)} ä¸ªmask")
        return filtered_masks
    
    # å¦‚æœæ£€æµ‹åˆ°çš„è¡Œåˆ—æ•°è¶³å¤Ÿï¼Œç­›é€‰è§„åˆ™çš„ç½‘æ ¼
    # é€‰æ‹©ä¸­é—´éƒ¨åˆ†ç»„æˆç›®æ ‡ç½‘æ ¼
    if len(row_y_means) >= target_rows:
        # é€‰æ‹©ä¸­é—´çš„target_rowsè¡Œ
        excess = len(row_y_means) - target_rows
        start_idx = excess // 2
        selected_row_labels = [row_y_means[i][0] for i in range(start_idx, start_idx + target_rows)]
    elif len(row_y_means) > 0:
        # å¦‚æœè¡Œæ•°ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰è¡Œ
        selected_row_labels = [r[0] for r in row_y_means]
    else:
        selected_row_labels = []
    
    if len(col_x_means) >= target_cols:
        # é€‰æ‹©ä¸­é—´çš„target_colsåˆ—
        excess = len(col_x_means) - target_cols
        start_idx = excess // 2
        selected_col_labels = [col_x_means[i][0] for i in range(start_idx, start_idx + target_cols)]
    elif len(col_x_means) > 0:
        # å¦‚æœåˆ—æ•°ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰åˆ—
        selected_col_labels = [c[0] for c in col_x_means]
    else:
        selected_col_labels = []
    
    # ç­›é€‰å‡ºåœ¨é€‰ä¸­è¡Œåˆ—ä¸­çš„mask
    filtered_masks = []
    for i, m in enumerate(main_masks):
        y_label = y_clustering.labels_[i]
        x_label = x_clustering.labels_[i]
        if y_label in selected_row_labels and x_label in selected_col_labels:
            filtered_masks.append(m)
    
    # å¦‚æœç­›é€‰åæ•°é‡ä¸è¶³ï¼ŒæŒ‰ä½ç½®æ’åºè¡¥é½
    if len(filtered_masks) < target_rows * target_cols:
        print(f"   âš ï¸ ç­›é€‰åæ•°é‡ä¸è¶³({len(filtered_masks)})ï¼ŒæŒ‰ä½ç½®è¡¥é½...")
        # æŒ‰ä½ç½®æ’åºæ‰€æœ‰å€™é€‰mask
        main_masks.sort(key=lambda m: (m['bbox'][1], m['bbox'][0]))
        # å¦‚æœå€™é€‰maskè¶³å¤Ÿï¼Œè¡¥é½åˆ°ç›®æ ‡æ•°é‡
        if len(main_masks) >= target_rows * target_cols:
            filtered_masks = main_masks[:target_rows * target_cols]
        else:
            filtered_masks = main_masks
    elif len(filtered_masks) > target_rows * target_cols:
        # å¦‚æœç­›é€‰åæ•°é‡è¿‡å¤šï¼ŒæŒ‰é¢ç§¯å’Œä½ç½®è¿›ä¸€æ­¥ç­›é€‰
        print(f"   âš ï¸ ç­›é€‰åæ•°é‡è¿‡å¤š({len(filtered_masks)})ï¼Œè¿›ä¸€æ­¥ç­›é€‰...")
        # è®¡ç®—å¹³å‡é¢ç§¯
        filtered_areas = [m['area'] for m in filtered_masks]
        median_filtered_area = np.median(filtered_areas)
        
        # æŒ‰é¢ç§¯æ¥è¿‘ä¸­ä½æ•°å’Œä½ç½®æ’åº
        filtered_masks_with_score = []
        for m in filtered_masks:
            area = m['area']
            # é¢ç§¯å¾—åˆ†ï¼šè¶Šæ¥è¿‘ä¸­ä½æ•°å¾—åˆ†è¶Šé«˜
            area_score = 1.0 / (1.0 + abs(area - median_filtered_area) / median_filtered_area)
            filtered_masks_with_score.append((m, area_score))
        
        # å…ˆæŒ‰ä½ç½®æ’åºï¼Œç„¶åæŒ‰é¢ç§¯å¾—åˆ†æ’åº
        filtered_masks_with_score.sort(key=lambda x: (x[0]['bbox'][1], x[0]['bbox'][0], -x[1]))
        filtered_masks = [m for m, _ in filtered_masks_with_score[:target_rows * target_cols]]
    
    print(f"   âœ… æœ€ç»ˆç­›é€‰å: {len(filtered_masks)} ä¸ªmask")
    return filtered_masks


def process_image_with_sam_everything(lines_image_path, original_image_path, output_dir, image_name,
                                       points_per_side=32, pred_iou_thresh=0.86, 
                                       stability_score_thresh=0.92, min_mask_area=100, bbox_alpha=0.6):
    """
    ä½¿ç”¨SAM everythingæ¨¡å¼å¤„ç†çº¿æ®µå›¾åƒï¼Œå¹¶åœ¨åŸå›¾ä¸Šç»˜åˆ¶maskçš„çŸ©å½¢æ¡†
    
    Args:
        lines_image_path: çº¿æ®µå›¾åƒè·¯å¾„ï¼ˆall_lines.pngï¼‰
        original_image_path: åŸå›¾è·¯å¾„ï¼ˆç”¨äºç»˜åˆ¶çŸ©å½¢æ¡†ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        image_name: å›¾åƒåç§°
        points_per_side: SAMé‡‡æ ·ç‚¹å¯†åº¦
        pred_iou_thresh: é¢„æµ‹IOUé˜ˆå€¼
        stability_score_thresh: ç¨³å®šæ€§å¾—åˆ†é˜ˆå€¼
        min_mask_area: æœ€å°maské¢ç§¯
        bbox_alpha: çŸ©å½¢æ¡†é€æ˜åº¦ï¼ˆ0.0-1.0ï¼‰
    
    Returns:
        masks: SAMç”Ÿæˆçš„masksåˆ—è¡¨
    """
    # å»¶è¿ŸåŠ è½½SAMæ¨¡å‹
    try:
        sam, device = load_sam_model()
    except Exception as e:
        print(f"   âŒ SAMæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return []
    
    # è¯»å–çº¿æ®µå›¾åƒï¼ˆall_lines.pngï¼‰
    lines_img = cv2.imread(lines_image_path)
    if lines_img is None:
        print(f"   âŒ æ— æ³•è¯»å–çº¿æ®µå›¾åƒ: {lines_image_path}")
        return []
    
    lines_img_rgb = cv2.cvtColor(lines_img, cv2.COLOR_BGR2RGB)
    
    # åˆ›å»ºSAMè‡ªåŠ¨maskç”Ÿæˆå™¨ï¼ˆä½¿ç”¨å¯é…ç½®å‚æ•°ï¼‰
    from segment_anything.utils.transforms import ResizeLongestSide
    mask_generator = SamAutomaticMaskGenerator(
        model=sam,
        points_per_side=points_per_side,  # é‡‡æ ·ç‚¹å¯†åº¦
        pred_iou_thresh=pred_iou_thresh,  # é¢„æµ‹IOUé˜ˆå€¼
        stability_score_thresh=stability_score_thresh,  # ç¨³å®šæ€§å¾—åˆ†é˜ˆå€¼
        crop_n_layers=1,  # å‡å°‘è£å‰ªå±‚ï¼Œå‡å°‘ç»†åˆ†
        crop_n_points_downscale_factor=2,
        min_mask_region_area=min_mask_area,  # æœ€å°åŒºåŸŸé¢ç§¯
    )
    
    print(f"      SAMå‚æ•°: points={points_per_side}, iou={pred_iou_thresh}, stability={stability_score_thresh}, min_area={min_mask_area}")
    
    # ç”Ÿæˆmasks
    print(f"   ğŸ”„ æ­£åœ¨ç”Ÿæˆmasksï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
    masks = mask_generator.generate(lines_img_rgb)
    print(f"   âœ… ç”Ÿæˆ {len(masks)} ä¸ªmasks")
    
    # è¯»å–åŸå›¾
    original_img = cv2.imread(original_image_path)
    if original_img is None:
        print(f"   âŒ æ— æ³•è¯»å–åŸå›¾: {original_image_path}")
        return masks
    
    # ä¿å­˜maskå¯è§†åŒ–ï¼ˆæ•´å¼ å›¾åƒçš„maskå åŠ æ˜¾ç¤ºï¼‰
    mask_vis_img = lines_img_rgb.copy()
    if len(masks) > 0:
        # æŒ‰é¢ç§¯æ’åºï¼ˆä»å¤§åˆ°å°ï¼‰
        sorted_masks = sorted(masks, key=lambda x: x['area'], reverse=True)
        
        # ä¸ºæ¯ä¸ªmaskåˆ†é…ä¸€ä¸ªé¢œè‰²ï¼ˆä½¿ç”¨é€æ˜åº¦å åŠ ï¼‰
        overlay = mask_vis_img.copy().astype(np.float32)
        
        # è®¾ç½®éšæœºç§å­ä»¥è·å¾—å¯é‡å¤çš„é¢œè‰²
        np.random.seed(42)
        
        for i, mask_info in enumerate(sorted_masks):
            mask = mask_info['segmentation']  # 2D boolean array (H x W)
            # ä¸ºæ¯ä¸ªmaskç”Ÿæˆä¸€ä¸ªéšæœºé¢œè‰²
            color = np.random.randint(0, 255, 3)
            
            # åªå¯¹maskåŒºåŸŸç€è‰²ï¼ˆåŠé€æ˜ï¼‰
            # maskæ˜¯2Dçš„ï¼Œéœ€è¦æ‰©å±•åˆ°3Dæ¥åŒ¹é…overlayçš„shape
            mask_3d = mask[:, :, np.newaxis]  # (H x W x 1)
            
            # å¯¹æ¯ä¸ªé€šé“åˆ†åˆ«åº”ç”¨mask
            overlay[mask, 0] = overlay[mask, 0] * 0.5 + color[0] * 0.5
            overlay[mask, 1] = overlay[mask, 1] * 0.5 + color[1] * 0.5
            overlay[mask, 2] = overlay[mask, 2] * 0.5 + color[2] * 0.5
        
        mask_vis_img = overlay.astype(np.uint8)
    
    mask_vis_path = os.path.join(output_dir, f"{image_name}_sam_masks_visualization.png")
    cv2.imwrite(mask_vis_path, cv2.cvtColor(mask_vis_img, cv2.COLOR_RGB2BGR))
    print(f"   âœ… SAM maskså¯è§†åŒ–å·²ä¿å­˜: {mask_vis_path}")
    
    # æš‚æ—¶ä¸è¿‡æ»¤maskï¼Œç›´æ¥ä½¿ç”¨æ‰€æœ‰æ£€æµ‹åˆ°çš„mask
    print(f"   ğŸ“ æš‚ä¸è¿‡æ»¤maskï¼Œä¿ç•™æ‰€æœ‰æ£€æµ‹åˆ°çš„ {len(masks)} ä¸ªmask")
    
    # åœ¨åŸå›¾ä¸Šç»˜åˆ¶æ‰€æœ‰maskçš„çŸ©å½¢æ¡†ï¼ˆçº¢è‰²ï¼Œ1pxï¼ŒåŠé€æ˜ï¼‰
    # æ–¹æ³•ï¼šç›´æ¥ä½¿ç”¨SAMè¿”å›çš„bboxï¼ˆè½´å¯¹é½è¾¹ç•Œæ¡†ï¼‰
    overlay = original_img.copy()
    
    for i, mask_info in enumerate(masks):
        # SAMè‡ªåŠ¨è®¡ç®—çš„bboxï¼š[x, y, width, height]
        bbox = mask_info['bbox']  
        x, y, w, h = bbox
        
        # ç»˜åˆ¶çŸ©å½¢æ¡†ï¼ˆçº¢è‰²ï¼Œ1pxï¼‰
        cv2.rectangle(overlay, (int(x), int(y)), (int(x + w), int(y + h)), (0, 0, 255), 1)
    
    # å åŠ åŠé€æ˜æ•ˆæœ
    vis_img = cv2.addWeighted(overlay, bbox_alpha, original_img, 1 - bbox_alpha, 0)
    
    # ä¿å­˜ç»“æœ
    output_path = os.path.join(output_dir, f"{image_name}_sam_masks_bboxes.png")
    cv2.imwrite(output_path, vis_img)
    print(f"   âœ… æ‰€æœ‰maskçŸ©å½¢æ¡†å·²ä¿å­˜: {output_path} (å…±{len(masks)}ä¸ªï¼Œ1pxåŠé€æ˜Î±={bbox_alpha})")
    
    
    # ä¿å­˜masksä¿¡æ¯ï¼ˆJSONï¼‰
    masks_json_path = os.path.join(output_dir, f"{image_name}_sam_masks.json")
    masks_data = {
        "image": image_name,
        "mask_count": len(masks),
        "sam_config": {
            "points_per_side": points_per_side,
            "pred_iou_thresh": pred_iou_thresh,
            "stability_score_thresh": stability_score_thresh,
            "crop_n_layers": 1,
            "min_mask_region_area": min_mask_area
        },
        "masks": []
    }
    
    for i, mask_info in enumerate(masks):
        bbox = mask_info['bbox']
        masks_data["masks"].append({
            "id": i,
            "bbox": {
                "x": float(bbox[0]),
                "y": float(bbox[1]),
                "width": float(bbox[2]),
                "height": float(bbox[3])
            },
            "area": int(mask_info['area']),
            "predicted_iou": float(mask_info.get('predicted_iou', 0)),
            "stability_score": float(mask_info.get('stability_score', 0))
        })
    
    with open(masks_json_path, 'w', encoding='utf-8') as f:
        json.dump(masks_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… SAM masksä¿¡æ¯å·²ä¿å­˜: {masks_json_path}")
    
    return masks


def save_json_results(json_path, horizontal_lines, vertical_lines, image_name, image_size):
    """ä¿å­˜æ£€æµ‹ç»“æœåˆ°JSONæ–‡ä»¶"""
    result = {
        "image": image_name,
        "image_size": {"width": image_size[0], "height": image_size[1]},
        "method": "DeepLSD",
        "horizontal_lines": {
            "count": len(horizontal_lines),
            "lines": [
                {"x1": float(x1), "y1": float(y1), "x2": float(x2), "y2": float(y2)}
                for x1, y1, x2, y2 in horizontal_lines
            ]
        },
        "vertical_lines": {
            "count": len(vertical_lines),
            "lines": [
                {"x1": float(x1), "y1": float(y1), "x2": float(x2), "y2": float(y2)}
                for x1, y1, x2, y2 in vertical_lines
            ]
        }
    }
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ JSONç»“æœå·²ä¿å­˜: {json_path}")


def process_single_image(image_path, model, device, output_dir="deeplsd_results", 
                         min_length_ratio=0.05, endpoint_distance_threshold=10,
                         sam_points_per_side=32, sam_pred_iou_thresh=0.86, 
                         sam_stability_thresh=0.92, sam_min_area=100, area_tolerance=0.5, bbox_alpha=0.6):
    """
    å¤„ç†å•å¼ å›¾åƒï¼ˆæ”¯æŒå®½å›¾åƒè‡ªé€‚åº”ï¼‰
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        model: DeepLSDæ¨¡å‹
        device: è®¾å¤‡
        output_dir: è¾“å‡ºç›®å½•
        min_length_ratio: äºŒæ¬¡æ£€æµ‹çš„æœ€å°çº¿æ®µé•¿åº¦æ¯”ä¾‹ï¼ˆç›¸å¯¹å›¾åƒå¯¹è§’çº¿ï¼‰
        endpoint_distance_threshold: ç«–çº¿ç«¯ç‚¹åˆ°æ¨ªçº¿çš„è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
        sam_points_per_side: SAMé‡‡æ ·ç‚¹å¯†åº¦
        sam_pred_iou_thresh: SAMé¢„æµ‹IOUé˜ˆå€¼
        sam_stability_thresh: SAMç¨³å®šæ€§é˜ˆå€¼
        sam_min_area: SAMæœ€å°maské¢ç§¯
        area_tolerance: é¢ç§¯å®¹å·®èŒƒå›´ï¼ˆç›¸å¯¹ä¸­ä½æ•°ï¼‰
        bbox_alpha: çŸ©å½¢æ¡†é€æ˜åº¦ï¼ˆ0.0-1.0ï¼‰
    """
    print(f"\n{'='*60}")
    print(f"å¤„ç†å›¾åƒ: {image_path}")
    print(f"{'='*60}")
    
    # é¢„å…ˆè¯»å–å›¾åƒä»¥æ£€æµ‹å®½é«˜æ¯”
    test_img = cv2.imread(image_path)
    if test_img is None and PIL_AVAILABLE:
        try:
            pil_img = PILImage.open(image_path)
            if pil_img.mode != 'RGB':
                pil_img = pil_img.convert('RGB')
            test_img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        except:
            pass
    
    # è‡ªé€‚åº”å‚æ•°è°ƒæ•´ï¼ˆé’ˆå¯¹å®½å›¾åƒï¼‰
    if test_img is not None:
        img_h, img_w = test_img.shape[:2]
        aspect_ratio = img_w / img_h
        
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {img_w} Ã— {img_h} (å®½é«˜æ¯”: {aspect_ratio:.2f})")
        
        # å®½å›¾åƒè‡ªé€‚åº”è°ƒæ•´
        if aspect_ratio > 2.5:
            # è¶…å®½å›¾åƒï¼ˆå¦‚3åˆ—ä½œæ–‡æ ¼ï¼Œå®½é«˜æ¯”çº¦3.0ï¼‰
            print(f"âš™ï¸  æ£€æµ‹åˆ°è¶…å®½å›¾åƒï¼ˆå®½é«˜æ¯” > 2.5ï¼‰ï¼Œè‡ªåŠ¨è°ƒæ•´å‚æ•°ï¼š")
            
            # å¢åŠ SAMé‡‡æ ·ç‚¹å¯†åº¦
            original_points = sam_points_per_side
            sam_points_per_side = min(int(sam_points_per_side * 2.0), 64)
            print(f"   SAMé‡‡æ ·ç‚¹: {original_points} â†’ {sam_points_per_side} (x2å€)")
            
            # è°ƒæ•´ç«¯ç‚¹è·ç¦»é˜ˆå€¼
            original_threshold = endpoint_distance_threshold
            endpoint_distance_threshold = int(endpoint_distance_threshold * 1.5)
            print(f"   ç«¯ç‚¹è·ç¦»é˜ˆå€¼: {original_threshold} â†’ {endpoint_distance_threshold}px (x1.5å€)")
            
            # è°ƒæ•´æœ€å°é¢ç§¯
            original_min_area = sam_min_area
            sam_min_area = int(sam_min_area * 2.0)
            print(f"   SAMæœ€å°é¢ç§¯: {original_min_area} â†’ {sam_min_area}pxÂ² (x2å€)")
            
            # æ”¾å®½é¢ç§¯å®¹å·®
            original_tolerance = area_tolerance
            area_tolerance = min(area_tolerance * 1.5, 0.8)
            print(f"   é¢ç§¯å®¹å·®: {original_tolerance:.1f} â†’ {area_tolerance:.1f} (x1.5å€)")
            
        elif aspect_ratio > 1.8:
            # å®½å›¾åƒï¼ˆå¦‚2åˆ—ä½œæ–‡æ ¼ï¼‰
            print(f"âš™ï¸  æ£€æµ‹åˆ°å®½å›¾åƒï¼ˆå®½é«˜æ¯” > 1.8ï¼‰ï¼Œè°ƒæ•´å‚æ•°ï¼š")
            
            original_points = sam_points_per_side
            sam_points_per_side = min(int(sam_points_per_side * 1.5), 64)
            print(f"   SAMé‡‡æ ·ç‚¹: {original_points} â†’ {sam_points_per_side} (x1.5å€)")
            
            original_threshold = endpoint_distance_threshold
            endpoint_distance_threshold = int(endpoint_distance_threshold * 1.3)
            print(f"   ç«¯ç‚¹è·ç¦»é˜ˆå€¼: {original_threshold} â†’ {endpoint_distance_threshold}px (x1.3å€)")
            
            original_min_area = sam_min_area
            sam_min_area = int(sam_min_area * 1.5)
            print(f"   SAMæœ€å°é¢ç§¯: {original_min_area} â†’ {sam_min_area}pxÂ² (x1.5å€)")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–å›¾åƒåç§°
    image_name = Path(image_path).stem
    
    try:
        # æ£€æµ‹çº¿æ®µ
        lines, img_shape = detect_lines_deeplsd(image_path, model, device)
        
        # è½¬æ¢æ ¼å¼
        lines_standard = convert_lines_format(lines)
        
        # åˆ†ç±»æ¨ªçº¿å’Œç«–çº¿
        horizontal_lines, vertical_lines, other_lines = filter_horizontal_vertical(lines_standard)
        
        print(f"ğŸ“Š åˆ†ç±»ç»“æœ:")
        print(f"   æ¨ªçº¿: {len(horizontal_lines)} æ¡")
        print(f"   ç«–çº¿: {len(vertical_lines)} æ¡")
        if other_lines:
            print(f"   å…¶ä»–: {len(other_lines)} æ¡")
        
        # åˆå¹¶æ‰€æœ‰çº¿æ®µï¼ˆç”¨äºæå–çŸ©å½¢æ¡†ï¼‰
        all_lines = horizontal_lines + vertical_lines + other_lines
        print(f"   æ€»çº¿æ®µ: {len(all_lines)} æ¡")
        
        # æ ¹æ®æ–‡ä»¶åç¡®å®šç›®æ ‡ç½‘æ ¼å°ºå¯¸
        filename = Path(image_path).stem
        if filename.endswith('_B_03'):
            target_rows = 17
            target_cols = 16
            print(f"   ğŸ“‹ æ£€æµ‹åˆ°_B_03ç±»å‹ï¼Œç›®æ ‡: {target_rows}è¡Œ Ã— {target_cols}åˆ—")
        else:
            target_rows = 20
            target_cols = 16
            print(f"   ğŸ“‹ ç›®æ ‡ç½‘æ ¼: {target_rows}è¡Œ Ã— {target_cols}åˆ—")
        
        # === æ–°æ€è·¯ï¼šäºŒæ¬¡DeepLSDæ£€æµ‹ ===
        print(f"\nğŸ“ æ–°æ€è·¯ï¼šä½¿ç”¨DeepLSDäºŒæ¬¡æ£€æµ‹å»é™¤å¹²æ‰°çº¿...")
        
        # ç¬¬ä¸€æ­¥ï¼šç»˜åˆ¶æ‰€æœ‰åŸå§‹çº¿æ®µåˆ°å›¾åƒï¼ˆä¸è¿‡æ»¤ï¼‰
        print(f"   æ­¥éª¤1: ç»˜åˆ¶ç¬¬ä¸€æ¬¡æ£€æµ‹çš„æ‰€æœ‰çº¿æ®µ...")
        img_h, img_w = img_shape[:2]
        lines_image_raw = np.ones((img_h, img_w), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
        
        # ç»˜åˆ¶æ‰€æœ‰æ¨ªçº¿ï¼ˆé»‘è‰²ï¼Œ1pxï¼‰
        for x1, y1, x2, y2 in horizontal_lines:
            cv2.line(lines_image_raw, (int(x1), int(y1)), (int(x2), int(y2)), 0, 1)
        
        # ç»˜åˆ¶æ‰€æœ‰ç«–çº¿ï¼ˆé»‘è‰²ï¼Œ1pxï¼‰
        for x1, y1, x2, y2 in vertical_lines:
            cv2.line(lines_image_raw, (int(x1), int(y1)), (int(x2), int(y2)), 0, 1)
        
        # ä¿å­˜åŸå§‹çº¿æ®µå›¾åƒ
        lines_raw_path = os.path.join(output_dir, f"{image_name}_all_lines_raw.png")
        cv2.imwrite(lines_raw_path, lines_image_raw)
        print(f"   âœ… ç¬¬ä¸€æ¬¡æ£€æµ‹çš„æ‰€æœ‰çº¿æ®µå·²ä¿å­˜: {lines_raw_path}")
        print(f"      (æ¨ªçº¿: {len(horizontal_lines)}, ç«–çº¿: {len(vertical_lines)})")
        
        # ç¬¬äºŒæ­¥ï¼šç”¨DeepLSDå†æ¬¡æ£€æµ‹çº¯çº¿æ®µå›¾åƒï¼ˆæ¨ªçº¿å’Œç«–çº¿åˆ†åˆ«å¤„ç†ï¼‰
        print(f"\n   æ­¥éª¤2: ä½¿ç”¨DeepLSDäºŒæ¬¡æ£€æµ‹çº¯çº¿æ®µå›¾ï¼ˆåˆ†ç±»å¤„ç†æ¨¡å¼ï¼‰...")
        
        try:
            # ç­–ç•¥ï¼šæ¨ªçº¿ç”¨é•¿åº¦è¿‡æ»¤ï¼Œç«–çº¿ä¸è¿‡æ»¤ï¼ˆä¿ç•™çŸ­ç«–çº¿ï¼‰
            
            # 2.1 ç»˜åˆ¶ä»…åŒ…å«æ¨ªçº¿çš„å›¾åƒ
            print(f"      2.1 ç»˜åˆ¶çº¯æ¨ªçº¿å›¾...")
            h_lines_image = np.ones((img_h, img_w), dtype=np.uint8) * 255
            for x1, y1, x2, y2 in horizontal_lines:
                cv2.line(h_lines_image, (int(x1), int(y1)), (int(x2), int(y2)), 0, 1)
            h_lines_path = os.path.join(output_dir, f"{image_name}_horizontal_lines_raw.png")
            cv2.imwrite(h_lines_path, h_lines_image)
            
            # 2.2 ç»˜åˆ¶ä»…åŒ…å«ç«–çº¿çš„å›¾åƒ
            print(f"      2.2 ç»˜åˆ¶çº¯ç«–çº¿å›¾...")
            v_lines_image = np.ones((img_h, img_w), dtype=np.uint8) * 255
            for x1, y1, x2, y2 in vertical_lines:
                cv2.line(v_lines_image, (int(x1), int(y1)), (int(x2), int(y2)), 0, 1)
            v_lines_path = os.path.join(output_dir, f"{image_name}_vertical_lines_raw.png")
            cv2.imwrite(v_lines_path, v_lines_image)
            
            # 2.3 äºŒæ¬¡æ£€æµ‹æ¨ªçº¿ï¼ˆä½¿ç”¨é•¿åº¦è¿‡æ»¤ï¼‰
            print(f"      2.3 äºŒæ¬¡æ£€æµ‹æ¨ªçº¿ï¼ˆä½¿ç”¨é•¿åº¦è¿‡æ»¤ï¼‰...")
            img_diag = np.sqrt(img_h**2 + img_w**2)
            min_h_length = img_diag * min_length_ratio  # æ¨ªçº¿æœ€å°é•¿åº¦
            print(f"          æ¨ªçº¿å‚æ•°: min_length={min_h_length:.1f}px")
            
            h_lines_2nd, _ = detect_lines_deeplsd(
                h_lines_path, model, device,
                min_length=min_h_length,
                score_thresh=0.0,
                is_second_pass=True
            )
            h_lines_2nd_standard = convert_lines_format(h_lines_2nd)
            horizontal_lines_2nd, _, _ = filter_horizontal_vertical(h_lines_2nd_standard)
            
            # 2.4 äºŒæ¬¡æ£€æµ‹ç«–çº¿ï¼ˆä¸ä½¿ç”¨é•¿åº¦è¿‡æ»¤ï¼Œä¿ç•™çŸ­ç«–çº¿ï¼‰
            print(f"      2.4 äºŒæ¬¡æ£€æµ‹ç«–çº¿ï¼ˆä¸è¿‡æ»¤é•¿åº¦ï¼Œä¿ç•™çŸ­ç«–çº¿ï¼‰...")
            v_lines_2nd, _ = detect_lines_deeplsd(
                v_lines_path, model, device,
                min_length=0,  # ä¸è¿‡æ»¤é•¿åº¦
                score_thresh=0.0,
                is_second_pass=True
            )
            v_lines_2nd_standard = convert_lines_format(v_lines_2nd)
            _, vertical_lines_2nd, _ = filter_horizontal_vertical(v_lines_2nd_standard)
            
            # 2.5 æ ¹æ®ç«¯ç‚¹è¿‡æ»¤ç«–çº¿ï¼ˆåªä¿ç•™ä¸Šä¸‹ä¸¤ç«¯éƒ½æ¥è¿‘æ¨ªçº¿çš„ï¼‰
            print(f"      2.5 æ ¹æ®ç«¯ç‚¹è¿‡æ»¤ç«–çº¿ï¼ˆè·ç¦»é˜ˆå€¼={endpoint_distance_threshold}pxï¼‰...")
            vertical_lines_2nd = filter_vertical_lines_by_endpoints(
                vertical_lines_2nd, 
                horizontal_lines_2nd,  # ä½¿ç”¨äºŒæ¬¡æ£€æµ‹åçš„æ¨ªçº¿
                distance_threshold=endpoint_distance_threshold  # ä½¿ç”¨é…ç½®çš„é˜ˆå€¼
            )
            
            print(f"   ğŸ“Š ç¬¬äºŒæ¬¡æ£€æµ‹å¯¹æ¯”:")
            print(f"      æ¨ªçº¿: {len(horizontal_lines)} -> {len(horizontal_lines_2nd)} (é•¿åº¦è¿‡æ»¤)")
            print(f"      ç«–çº¿: {len(vertical_lines)} -> {len(vertical_lines_2nd)} (ç«¯ç‚¹è¿‡æ»¤)")
            
            # ä½¿ç”¨ç¬¬äºŒæ¬¡æ£€æµ‹çš„ç»“æœ
            filtered_horizontal_lines = horizontal_lines_2nd
            filtered_vertical_lines = vertical_lines_2nd
            
        except Exception as e:
            print(f"   âš ï¸ ç¬¬äºŒæ¬¡æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿè¿‡æ»¤æ–¹æ³•: {e}")
            import traceback
            traceback.print_exc()
            # å¦‚æœç¬¬äºŒæ¬¡æ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°è¿‡æ»¤æ–¹æ³•
            filtered_horizontal_lines = filter_grid_lines(horizontal_lines, 'horizontal', img_shape)
            filtered_vertical_lines = filter_grid_lines(vertical_lines, 'vertical', img_shape)
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæœ€ç»ˆçš„çº¿æ®µå›¾åƒï¼ˆç”¨äºSAMå¤„ç†ï¼‰
        print(f"\n   æ­¥éª¤3: ç”Ÿæˆæœ€ç»ˆçº¿æ®µå›¾åƒ...")
        lines_image = np.ones((img_h, img_w), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
        
        # ç»˜åˆ¶è¿‡æ»¤åçš„æ¨ªçº¿ï¼ˆé»‘è‰²ï¼Œ1pxï¼‰
        for x1, y1, x2, y2 in filtered_horizontal_lines:
            cv2.line(lines_image, (int(x1), int(y1)), (int(x2), int(y2)), 0, 1)
        
        # ç»˜åˆ¶è¿‡æ»¤åçš„ç«–çº¿ï¼ˆé»‘è‰²ï¼Œ1pxï¼‰ç»Ÿä¸€çº¿å®½
        for x1, y1, x2, y2 in filtered_vertical_lines:
            cv2.line(lines_image, (int(x1), int(y1)), (int(x2), int(y2)), 0, 1)
        
        # ä¿å­˜æœ€ç»ˆçº¿æ®µå›¾åƒ
        lines_only_path = os.path.join(output_dir, f"{image_name}_all_lines.png")
        cv2.imwrite(lines_only_path, lines_image)
        print(f"   âœ… æœ€ç»ˆçº¿æ®µå›¾åƒå·²ä¿å­˜: {lines_only_path}")
        print(f"      (æ¨ªçº¿: {len(filtered_horizontal_lines)}, ç«–çº¿: {len(filtered_vertical_lines)})")
        
        # ä½¿ç”¨SAM everythingæ¨¡å¼å¤„ç† all_lines.png
        if SAM_AVAILABLE:
            print(f"\nğŸ” ä½¿ç”¨SAM everythingæ¨¡å¼å¤„ç† {lines_only_path}...")
            try:
                sam_masks = process_image_with_sam_everything(
                    lines_only_path, 
                    image_path,  # åŸå›¾è·¯å¾„ï¼Œç”¨äºç»˜åˆ¶çŸ©å½¢æ¡†
                    output_dir,
                    image_name,
                    points_per_side=sam_points_per_side,
                    pred_iou_thresh=sam_pred_iou_thresh,
                    stability_score_thresh=sam_stability_thresh,
                    min_mask_area=sam_min_area,
                    bbox_alpha=bbox_alpha
                )
                print(f"   âœ… SAMå¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(sam_masks)} ä¸ªmasks")
                
                # æŒ‰é¢ç§¯è¿‡æ»¤ï¼Œå»é™¤å¼‚å¸¸å¤§å°çš„mask
                if len(sam_masks) > 0:
                    print(f"\n   æ­¥éª¤4: æŒ‰é¢ç§¯è¿‡æ»¤mask...")
                    filtered_masks = filter_masks_by_area(sam_masks, area_tolerance=area_tolerance)
                    
                    if len(filtered_masks) > 0:
                        # åœ¨åŸå›¾ä¸Šç»˜åˆ¶ç»ˆç‰ˆæ£€æµ‹æ¡†ï¼ˆè“è‰²ï¼Œ1pxï¼ŒåŠé€æ˜ï¼‰
                        print(f"   æ­¥éª¤5: ç»˜åˆ¶ç»ˆç‰ˆæ£€æµ‹æ¡†...")
                        original_img = cv2.imread(image_path)
                        if original_img is not None:
                            # åˆ›å»ºoverlayå±‚ç”¨äºåŠé€æ˜ç»˜åˆ¶
                            overlay = original_img.copy()
                            
                            for mask_info in filtered_masks:
                                bbox = mask_info['bbox']
                                x, y, w, h = bbox
                                # ç»˜åˆ¶è“è‰²çŸ©å½¢æ¡†ï¼ˆ1pxï¼‰
                                cv2.rectangle(overlay, (int(x), int(y)), (int(x + w), int(y + h)), (255, 0, 0), 1)
                            
                            # å åŠ åŠé€æ˜æ•ˆæœ
                            final_vis_img = cv2.addWeighted(overlay, bbox_alpha, original_img, 1 - bbox_alpha, 0)
                            
                            # ä¿å­˜ç»ˆç‰ˆæ£€æµ‹æ¡†å›¾åƒ
                            final_output_path = os.path.join(output_dir, f"{image_name}_final_bboxes.png")
                            cv2.imwrite(final_output_path, final_vis_img)
                            print(f"   âœ… ç»ˆç‰ˆæ£€æµ‹æ¡†å·²ä¿å­˜: {final_output_path} (å…±{len(filtered_masks)}ä¸ªï¼Œè“è‰²1pxåŠé€æ˜Î±={bbox_alpha})")
                            
                            # ä¿å­˜ç»ˆç‰ˆæ£€æµ‹æ¡†JSON
                            final_json_path = os.path.join(output_dir, f"{image_name}_final_bboxes.json")
                            final_json_data = {
                                "image": image_name,
                                "total_masks": len(sam_masks),
                                "filtered_masks": len(filtered_masks),
                                "filter_method": "area_median",
                                "bboxes": []
                            }
                            
                            for i, mask_info in enumerate(filtered_masks):
                                bbox = mask_info['bbox']
                                final_json_data["bboxes"].append({
                                    "id": i,
                                    "x": float(bbox[0]),
                                    "y": float(bbox[1]),
                                    "width": float(bbox[2]),
                                    "height": float(bbox[3]),
                                    "area": int(mask_info['area'])
                                })
                            
                            with open(final_json_path, 'w', encoding='utf-8') as f:
                                json.dump(final_json_data, f, ensure_ascii=False, indent=2)
                            print(f"   âœ… ç»ˆç‰ˆæ£€æµ‹æ¡†JSONå·²ä¿å­˜: {final_json_path}")
                            
                            # æ­¥éª¤6: ä½¿ç”¨ç»ˆç‰ˆæ£€æµ‹æ¡†è¿›è¡Œå­—ç¬¦æ£€æµ‹
                            print(f"\n   æ­¥éª¤6: å­—ç¬¦æ£€æµ‹ï¼ˆä½¿ç”¨SAM box promptï¼‰...")
                            try:
                                char_results = process_char_detection_with_sam(
                                    image_path,
                                    final_json_data["bboxes"],
                                    output_dir,
                                    image_name,
                                    bbox_alpha=bbox_alpha
                                )
                                
                                if len(char_results) > 0:
                                    print(f"   âœ… å­—ç¬¦æ£€æµ‹å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {len(char_results)} ä¸ªå­—ç¬¦")
                                    
                                    # æ­¥éª¤7: åˆå¹¶ä¸¤ç§æ£€æµ‹æ¡†åˆ°ä¸€å¼ å›¾åƒ
                                    print(f"\n   æ­¥éª¤7: ç”Ÿæˆåˆå¹¶æ£€æµ‹æ¡†å›¾åƒ...")
                                    try:
                                        # åˆ›å»ºoverlayå±‚
                                        combined_overlay = original_img.copy()
                                        
                                        # å…ˆç»˜åˆ¶æ‰€æœ‰è“è‰²ä½œæ–‡æ ¼æ¡†ï¼ˆå¤–æ¡†ï¼‰
                                        for mask_info in filtered_masks:
                                            bbox = mask_info['bbox']
                                            x, y, w, h = bbox
                                            cv2.rectangle(combined_overlay, (int(x), int(y)), (int(x + w), int(y + h)), (255, 0, 0), 1)
                                        
                                        # å†ç»˜åˆ¶çº¢è‰²å­—ç¬¦æ¡†ï¼ˆå†…æ¡†ï¼Œåªæœ‰æœ‰å­—ç¬¦çš„ï¼‰
                                        for char_result in char_results:
                                            char_bbox = char_result['char_bbox']
                                            cx = char_bbox['x']
                                            cy = char_bbox['y']
                                            cw = char_bbox['width']
                                            ch = char_bbox['height']
                                            cv2.rectangle(combined_overlay, (cx, cy), (cx + cw, cy + ch), (0, 0, 255), 1)
                                        
                                        # å åŠ åŠé€æ˜æ•ˆæœ
                                        combined_vis_img = cv2.addWeighted(combined_overlay, bbox_alpha, original_img, 1 - bbox_alpha, 0)
                                        
                                        # åœ¨å›¾åƒé¡¶éƒ¨æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                                        text = f"Blue Boxes: {len(filtered_masks)}  |  Red Boxes: {len(char_results)}"
                                        font = cv2.FONT_HERSHEY_SIMPLEX
                                        font_scale = 1.0
                                        font_thickness = 2
                                        
                                        # è·å–æ–‡æœ¬å°ºå¯¸
                                        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, font_thickness)
                                        
                                        # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯æ¡
                                        bg_height = text_height + baseline + 20
                                        bg_overlay = combined_vis_img.copy()
                                        cv2.rectangle(bg_overlay, (0, 0), (combined_vis_img.shape[1], bg_height), (0, 0, 0), -1)
                                        combined_vis_img = cv2.addWeighted(bg_overlay, 0.6, combined_vis_img, 0.4, 0)
                                        
                                        # ç»˜åˆ¶ç™½è‰²æ–‡å­—
                                        text_x = 10
                                        text_y = text_height + 10
                                        cv2.putText(combined_vis_img, text, (text_x, text_y), font, font_scale, (255, 255, 255), font_thickness, cv2.LINE_AA)
                                        
                                        # ä¿å­˜åˆå¹¶å›¾åƒ
                                        combined_path = os.path.join(output_dir, f"{image_name}_combined_detection.png")
                                        cv2.imwrite(combined_path, combined_vis_img)
                                        print(f"   âœ… åˆå¹¶æ£€æµ‹æ¡†å·²ä¿å­˜: {combined_path}")
                                        print(f"      ğŸ“¦ è“è‰²=ä½œæ–‡æ ¼æ¡†({len(filtered_masks)}ä¸ª) + çº¢è‰²=å­—ç¬¦æ¡†({len(char_results)}ä¸ª)")
                                    except Exception as e:
                                        print(f"   âš ï¸ åˆå¹¶å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
                                else:
                                    print(f"   âš ï¸ æœªæ£€æµ‹åˆ°å­—ç¬¦")
                            except Exception as e:
                                print(f"   âš ï¸ å­—ç¬¦æ£€æµ‹å¤±è´¥: {e}")
                                import traceback
                                traceback.print_exc()
                        else:
                            print(f"   âš ï¸ æ— æ³•è¯»å–åŸå›¾: {image_path}")
                    else:
                        print(f"   âš ï¸ é¢ç§¯è¿‡æ»¤åæ²¡æœ‰å‰©ä½™mask")
                else:
                    print(f"   âš ï¸ SAMæœªæ£€æµ‹åˆ°ä»»ä½•mask")
                    
            except Exception as e:
                print(f"   âš ï¸ SAMå¤„ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        else:
            print(f"   âš ï¸ SAMæœªå®‰è£…ï¼Œè·³è¿‡SAMå¤„ç†")
        
        # å¯è§†åŒ–ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
        vis_path = os.path.join(output_dir, f"{image_name}_deeplsd_visual.png")
        visualize_lines(image_path, horizontal_lines, vertical_lines, vis_path)
        
        # ä¿å­˜æ–‡æœ¬ç»“æœï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
        txt_path = os.path.join(output_dir, f"{image_name}_deeplsd_lines.txt")
        save_results(txt_path, horizontal_lines, vertical_lines, image_name)
        
        # ä¿å­˜JSONç»“æœï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
        json_path = os.path.join(output_dir, f"{image_name}_deeplsd_lines.json")
        save_json_results(json_path, horizontal_lines, vertical_lines, image_name, 
                         (img_shape[1], img_shape[0]))
        
        print(f"âœ… å¤„ç†å®Œæˆ: {image_name}\n")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    # ========== é…ç½®åŒºåŸŸ ==========
    INPUT_FOLDER = "png"  # PNGæ–‡ä»¶å¤¹
    OUTPUT_DIR = "deeplsd_results"  # è¾“å‡ºç›®å½•
    MODEL_PATH = None  # æ¨¡å‹è·¯å¾„ï¼ŒNoneåˆ™è‡ªåŠ¨æŸ¥æ‰¾
    DEVICE = 'cuda'  # 'cuda' æˆ– 'cpu'
    
    # DeepLSDæ¨¡å‹å‚æ•°
    GRAD_THRESH = 3  # æ¢¯åº¦é˜ˆå€¼ï¼ˆ3=æ­£å¸¸ï¼Œ5-10=æ›´ä¸¥æ ¼ï¼Œå»é™¤æ›´å¤šå¹²æ‰°çº¿ï¼‰
    MERGE_LINES = True  # æ˜¯å¦åˆå¹¶ç›¸è¿‘çº¿æ®µ
    
    # äºŒæ¬¡æ£€æµ‹å‚æ•°
    MIN_LENGTH_RATIO = 0.05  # æ¨ªçº¿æœ€å°é•¿åº¦æ¯”ä¾‹ï¼ˆç›¸å¯¹å›¾åƒå¯¹è§’çº¿ï¼Œ0.05=5%ï¼‰
    
    # ç«–çº¿ç«¯ç‚¹è¿‡æ»¤å‚æ•°
    ENDPOINT_DISTANCE_THRESHOLD = 10  # ç«–çº¿ç«¯ç‚¹åˆ°æ¨ªçº¿çš„è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼Œæ¨è5-15ï¼‰
    
    # SAMå‚æ•°ï¼ˆè°ƒæ•´æ£€æµ‹å¯†åº¦ï¼Œé˜²æ­¢è¿‡åº¦åˆ†å‰²ï¼‰
    SAM_POINTS_PER_SIDE = 40  # é‡‡æ ·ç‚¹å¯†åº¦ï¼ˆ16=ç¨€ç–ï¼Œ32=é€‚ä¸­ï¼Œ40=è¾ƒå¯†ï¼Œ64=å¯†é›†ï¼‰
    SAM_PRED_IOU_THRESH = 0.82  # é¢„æµ‹IOUé˜ˆå€¼ï¼ˆè¶Šé«˜è¶Šä¸¥æ ¼ï¼Œæ¨è0.8-0.95ï¼‰
    SAM_STABILITY_THRESH = 0.88  # ç¨³å®šæ€§é˜ˆå€¼ï¼ˆè¶Šé«˜è¶Šä¸¥æ ¼ï¼Œæ¨è0.85-0.95ï¼‰
    SAM_MIN_AREA = 70  # æœ€å°maské¢ç§¯ï¼ˆåƒç´ ï¼Œè¿‡æ»¤ç¢ç‰‡ï¼‰
    
    # é¢ç§¯è¿‡æ»¤å‚æ•°
    AREA_TOLERANCE = 0.5  # é¢ç§¯å®¹å·®èŒƒå›´ï¼ˆç›¸å¯¹ä¸­ä½æ•°ï¼Œ0.5=ä¸­ä½æ•°çš„50%-150%ï¼‰
    
    # å¯è§†åŒ–å‚æ•°
    BBOX_ALPHA = 0.6  # çŸ©å½¢æ¡†é€æ˜åº¦ï¼ˆ0.0=å®Œå…¨é€æ˜ï¼Œ1.0=å®Œå…¨ä¸é€æ˜ï¼Œæ¨è0.5-0.8ï¼‰
    # ========== é…ç½®åŒºåŸŸç»“æŸ ==========
    
    print("="*60)
    print("DeepLSD æ¨ªçº¿ç«–çº¿æ£€æµ‹å·¥å…· (äºŒæ¬¡æ£€æµ‹å»å¹²æ‰°æ¨¡å¼)")
    print("="*60)
    print(f"ğŸ”§ DeepLSDé…ç½®: grad_thresh={GRAD_THRESH}, min_length_ratio={MIN_LENGTH_RATIO*100}%")
    print(f"ğŸ“‹ ç­–ç•¥: æ¨ªçº¿ç”¨é•¿åº¦è¿‡æ»¤ï¼Œç«–çº¿ç”¨ç«¯ç‚¹è¿‡æ»¤ï¼ˆé˜ˆå€¼={ENDPOINT_DISTANCE_THRESHOLD}pxï¼‰")
    print(f"ğŸ¯ SAMé…ç½®: points={SAM_POINTS_PER_SIDE}, iou={SAM_PRED_IOU_THRESH}, stability={SAM_STABILITY_THRESH}, min_area={SAM_MIN_AREA}")
    print(f"ğŸ“ é¢ç§¯è¿‡æ»¤: tolerance=Â±{AREA_TOLERANCE*100:.0f}% (ä¿ç•™ä¸­ä½æ•°çš„{(1-AREA_TOLERANCE)*100:.0f}%-{(1+AREA_TOLERANCE)*100:.0f}%)")
    
    # æ£€æŸ¥DeepLSDæ˜¯å¦å¯ç”¨
    if not DEEPLSD_AVAILABLE:
        print("\nâŒ DeepLSDæœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
        print("\nğŸ’¡ è¯·ç¡®ä¿:")
        print("  1. DeepLSD æ–‡ä»¶å¤¹å­˜åœ¨")
        print("  2. å·²å®‰è£…å¿…è¦çš„ä¾èµ–ï¼ˆPyTorchç­‰ï¼‰")
        print("  3. å·²ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶")
        return
    
    # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
    try:
        model, device = load_deeplsd_model(
            model_path=MODEL_PATH, 
            device=DEVICE,
            grad_thresh=GRAD_THRESH,
            merge_lines=MERGE_LINES
        )
    except Exception as e:
        print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶å¤¹
    if not os.path.exists(INPUT_FOLDER):
        print(f"âŒ è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {INPUT_FOLDER}")
        return
    
    # è·å–æ‰€æœ‰PNGå’ŒTIFæ–‡ä»¶
    folder = Path(INPUT_FOLDER)
    image_files = []
    
    # æ”¯æŒå¤šç§æ ¼å¼
    for ext in ['*.png', '*.PNG', '*.tif', '*.tiff', '*.TIF', '*.TIFF']:
        image_files.extend(list(folder.glob(ext)))
    
    # æ’åºå¹¶å»é‡
    image_files = sorted(list(set(image_files)))
    
    if len(image_files) == 0:
        print(f"âš ï¸ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {INPUT_FOLDER}/*.png æˆ– *.tif")
        return
    
    print(f"\nğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶ï¼ˆpng/tifæ ¼å¼ï¼‰")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_DIR}\n")
    
    # å¤„ç†æ¯å¼ å›¾åƒ
    for i, img_path in enumerate(image_files, 1):
        print(f"[{i}/{len(image_files)}] å¤„ç†: {img_path.name}")
        process_single_image(
            str(img_path), 
            model, 
            device, 
            output_dir=OUTPUT_DIR,
            min_length_ratio=MIN_LENGTH_RATIO,
            endpoint_distance_threshold=ENDPOINT_DISTANCE_THRESHOLD,
            sam_points_per_side=SAM_POINTS_PER_SIDE,
            sam_pred_iou_thresh=SAM_PRED_IOU_THRESH,
            sam_stability_thresh=SAM_STABILITY_THRESH,
            sam_min_area=SAM_MIN_AREA,
            area_tolerance=AREA_TOLERANCE,
            bbox_alpha=BBOX_ALPHA
        )
    
    print(f"\n{'='*60}")
    print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {OUTPUT_DIR}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()

